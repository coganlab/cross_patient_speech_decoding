{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "629c8e9894f680c6",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9de9524454a74a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:36:37.423150Z",
     "start_time": "2024-07-10T12:36:26.252451Z"
    }
   },
   "outputs": [],
   "source": [
    "# %% Imports\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint, LearningRateMonitor\n",
    "from pytorch_lightning.utilities.model_summary import summarize\n",
    "import torch\n",
    "import numpy as np\n",
    "from data_utils.datamodules import SimpleMicroDataModule, AlignedMicroDataModule\n",
    "from models import CNNTransformer, Transformer, TCN_classifier, TemporalConvRNN, Seq2SeqRNN\n",
    "import data_utils.augmentations as augs\n",
    "import csv\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from alignment import alignment_utils as utils\n",
    "from alignment.AlignCCA import AlignCCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae402b0e2a9fc07",
   "metadata": {},
   "source": [
    "# Define data module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a46a71918adb132d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:36:42.704611Z",
     "start_time": "2024-07-10T12:36:37.423150Z"
    }
   },
   "outputs": [],
   "source": [
    "data_filename = os.path.expanduser('~/data/pt_decoding_data_S62.pkl')\n",
    "# data_filename = ('../data/pt_decoding_data_S62.pkl')\n",
    "pt_data = utils.load_pkl(data_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ced55da2478416b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:36:42.715275Z",
     "start_time": "2024-07-10T12:36:42.704611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(148, 200, 111), (148,), (148, 3)]\n",
      "[[(144, 200, 111), (144,), (144, 3)], [(151, 200, 63), (151,), (151, 3)], [(46, 200, 149), (46,), (46, 3)], [(151, 200, 74), (151,), (151, 3)], [(137, 200, 144), (137,), (137, 3)], [(141, 200, 171), (141,), (141, 3)], [(178, 200, 201), (178,), (178, 3)]]\n"
     ]
    }
   ],
   "source": [
    "pt = 'S26'\n",
    "p_ind = 1\n",
    "lab_type = 'phon'\n",
    "algn_type = 'phon_seq'\n",
    "tar_data, pre_data = utils.decoding_data_from_dict(pt_data, pt, p_ind,\n",
    "                                                   lab_type=lab_type,\n",
    "                                                   algn_type=algn_type)\n",
    "print([d.shape for d in tar_data])\n",
    "print([[d.shape for d in p] for p in pre_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b30a66092a23064f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:37:23.778265Z",
     "start_time": "2024-07-10T12:36:42.715275Z"
    }
   },
   "outputs": [],
   "source": [
    "fold_data_path = os.path.expanduser('~/workspace/transformer_data')\n",
    "# fold_data_path = '.'\n",
    "\n",
    "fs = 200 # Hz\n",
    "# augmentations = [augs.time_warping, augs.time_masking, augs.time_shifting, augs.noise_jitter, augs.scaling]\n",
    "augmentations = [augs.time_shifting, augs.noise_jitter, augs.scaling]\n",
    "# augmentations = None\n",
    "# data = torch.rand(n_samples, n_timepoints, n_features)\n",
    "# labels = torch.randint(0, 9, (n_samples,))\n",
    "# data = torch.Tensor(all_pt_dict['S14']['X1'])\n",
    "# labels = torch.Tensor(all_pt_dict['S14']['y1']).long() - 1\n",
    "data = torch.Tensor(tar_data[0])\n",
    "labels = torch.Tensor(tar_data[1]).long().unsqueeze(1) - 1\n",
    "align_labels = torch.Tensor(tar_data[2]).long() - 1\n",
    "# pool_data = [(torch.Tensor(p[0]), torch.Tensor(p[1]).long().unsqueeze(1) - 1, torch.Tensor(p[2]).long() - 1) for p in pre_data]\n",
    "pool_data = [(torch.Tensor(p[0]), torch.Tensor(p[2]).long() - 1, torch.Tensor(p[2]).long() - 1) for p in pre_data]  # for seq2seq RNN\n",
    "# data = torch.Tensor(all_pt_dict['S14']['X_collapsed'])\n",
    "# labels = torch.Tensor(all_pt_dict['S14']['y_phon_collapsed']).long() - 1\n",
    "\n",
    "# create the data module\n",
    "batch_size = 5000\n",
    "n_folds = 20\n",
    "val_size = 0.1\n",
    "\n",
    "context_prefix = 'ptSpecific'\n",
    "# dm = SimpleMicroDataModule(data, labels, batch_size=batch_size, folds=n_folds,\n",
    "#                            val_size=val_size, augmentations=augmentations, data_path=os.path.expanduser('~/workspace/transformer_data/pt_specific'))\n",
    "## modification of labels for seq2seq RNN ###\n",
    "# dm = SimpleMicroDataModule(data, align_labels, batch_size=batch_size, folds=n_folds,\n",
    "#                            val_size=val_size, augmentations=augmentations, data_path=os.path.expanduser('~/workspace/transformer_data/pt_specific'))\n",
    "\n",
    "# context_prefix = 'pooled'\n",
    "# # dm = AlignedMicroDataModule(data, labels, align_labels, pool_data, AlignCCA,\n",
    "# #                             batch_size=batch_size, folds=n_folds, val_size=val_size,\n",
    "# #                             augmentations=augmentations, data_path=fold_data_path)\n",
    "dm = AlignedMicroDataModule(data, align_labels, align_labels, pool_data, AlignCCA,\n",
    "                            batch_size=batch_size, folds=n_folds, val_size=val_size,\n",
    "                            augmentations=augmentations, data_path=fold_data_path)\n",
    "# dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98fad2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4352, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.train_dataloader().dataset.tensors[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1e18287490630e",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffdeb3bdad199307",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:37:23.785482Z",
     "start_time": "2024-07-10T12:37:23.778265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  | Name          | Type             | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | criterion     | CrossEntropyLoss | 0      | train\n",
      "1 | temporal_conv | TemporalConv     | 111 K  | train\n",
      "2 | encoder       | EncoderRNN       | 6.3 M  | train\n",
      "3 | decoder       | DecoderRNN       | 1.5 M  | train\n",
      "-----------------------------------------------------------\n",
      "7.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.9 M     Total params\n",
      "31.743    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/group/coganlab/zms14/miniconda3/envs/micro_decode/lib/python3.11/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.utilities.model_summary import summarize\n",
    "\n",
    "\n",
    "gclip_val = 0.5\n",
    "\n",
    "##### CNN TRANSFORMER #####\n",
    "\n",
    "# # model parameters\n",
    "# in_channels = data.shape[-1]\n",
    "# num_classes = 9\n",
    "# d_model = 128\n",
    "# # d_model = data.shape[-1]\n",
    "# kernel_time = 50  # ms\n",
    "# kernel_size = int(kernel_time * fs / 1000)  # kernel length in samples\n",
    "# stride_time = 25  # ms\n",
    "# stride = int(stride_time * fs / 1000)  # stride length in samples\n",
    "# padding = 0\n",
    "# n_head = 8\n",
    "# num_layers = 2\n",
    "# dim_fc = 64\n",
    "# # dim_fc = [128, 256, 128, 64]\n",
    "# cnn_dropout = 0.3\n",
    "# tform_dropout = 0.4\n",
    "# learning_rate = 5e-4\n",
    "# l2_reg = 1e-5\n",
    "# gclip_val = 0.5\n",
    "# activ = True\n",
    "\n",
    "# sum_model = CNNTransformer(in_channels, num_classes, d_model, kernel_size, stride, padding,\n",
    "#                            n_head, num_layers, dim_fc, cnn_dropout, tform_dropout, learning_rate)\n",
    "\n",
    "\n",
    "##### Temporal CNN classifier #####\n",
    "\n",
    "# # model parameters\n",
    "# in_channels = data.shape[-1]\n",
    "# num_classes = 9\n",
    "# kernel_time = 50  # ms\n",
    "# kernel_size = int(kernel_time * fs / 1000)  # kernel length in samples\n",
    "# stride_time = 25  # ms\n",
    "# stride = int(stride_time * fs / 1000)  # stride length in samples\n",
    "# padding = 0\n",
    "# dim_fc = [128, 256, 128, 64]\n",
    "# cnn_dropout = 0.3\n",
    "# learning_rate = 5e-4\n",
    "# l2_reg = 1e-5\n",
    "# gclip_val = 0.5\n",
    "# activ = True\n",
    "\n",
    "# sum_model = TCN_classifier(in_channels, num_classes, dim_fc, kernel_size, stride, padding,\n",
    "#                            cnn_dropout, learning_rate, l2_reg)\n",
    "\n",
    "\n",
    "##### Temporal CNN GRU #####\n",
    "\n",
    "# # model parameters\n",
    "# in_channels = data.shape[-1]\n",
    "# num_classes = 9\n",
    "# n_filters = 100\n",
    "# # d_model = data.shape[-1]\n",
    "# kernel_time = 50  # ms\n",
    "# kernel_size = int(kernel_time * fs / 1000)  # kernel length in samples\n",
    "# stride_time = 25  # ms\n",
    "# stride = int(stride_time * fs / 1000)  # stride length in samples\n",
    "# padding = 0\n",
    "# n_layers = 1\n",
    "# hidden_size = 500\n",
    "# dim_fc = [128, 64]\n",
    "# cnn_dropout = 0.3\n",
    "# rnn_dropout = 0.4\n",
    "# learning_rate = 5e-4\n",
    "# l2_reg = 1e-5\n",
    "# activ = True\n",
    "\n",
    "# sum_model = TemporalConvRNN(in_channels, n_filters, num_classes, hidden_size, n_layers,\n",
    "#                             kernel_size, dim_fc, stride, padding, cnn_dropout,\n",
    "#                             rnn_dropout, learning_rate, l2_reg)\n",
    "\n",
    "\n",
    "\n",
    "##### Seq2Seq RNN #####\n",
    "# model parameters\n",
    "in_channels = data.shape[-1]\n",
    "num_classes = 9\n",
    "n_filters = 100\n",
    "# d_model = data.shape[-1]\n",
    "kernel_time = 50  # ms\n",
    "kernel_size = int(kernel_time * fs / 1000)  # kernel length in samples\n",
    "stride_time = 50  # ms\n",
    "stride = int(stride_time * fs / 1000)  # stride length in samples\n",
    "padding = 0\n",
    "n_enc_layers = 2\n",
    "n_dec_layers = 1\n",
    "hidden_size = 500\n",
    "cnn_dropout = 0.3\n",
    "rnn_dropout = 0.3\n",
    "learning_rate = 1e-4\n",
    "l2_reg = 1e-5\n",
    "activ = False\n",
    "model_type = 'gru'\n",
    "\n",
    "sum_model = Seq2SeqRNN(in_channels, n_filters, hidden_size, num_classes, n_enc_layers,\n",
    "                       n_dec_layers, kernel_size, stride, padding, cnn_dropout,\n",
    "                       rnn_dropout, model_type, learning_rate, l2_reg)\n",
    "\n",
    "print(summarize(sum_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad31833df23d804b",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b5454c4b162770f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:37:24.423208Z",
     "start_time": "2024-07-10T12:37:24.417362Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")\n",
    "warnings.filterwarnings(\"ignore\", \"The number of training batches.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b1f762b11299743",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:37:24.431450Z",
     "start_time": "2024-07-10T12:37:24.423208Z"
    }
   },
   "outputs": [],
   "source": [
    "# instantiate the trainer\n",
    "max_epochs = 500\n",
    "# es_pat = max_steps // 20\n",
    "# max_steps = 500\n",
    "es_pat = 50\n",
    "warmup = 100\n",
    "# callbacks = [EarlyStopping(monitor='val_loss', patience=10)]\n",
    "log_dir = os.path.expanduser('~/workspace/transformer_data/transformer_logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddb5ecc37742fee3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:37:24.439028Z",
     "start_time": "2024-07-10T12:37:24.431450Z"
    }
   },
   "outputs": [],
   "source": [
    "# class MetricCollector(L.Callback):\n",
    "#     def __init__(self):\n",
    "#         self.metrics = {}\n",
    "#     \n",
    "#     def on_validation_epoch_end(self, trainer, pl_module):\n",
    "#         self.metrics['val_loss'] = trainer.logger.metrics['val_loss']\n",
    "#         self.metrics['val_acc'] = trainer.logger.metrics['val_acc']\n",
    "#     \n",
    "#     def on_test_epoch_end(self, trainer, pl_module):\n",
    "#         self.metrics['test_loss'] = trainer.logger.metrics['test_loss']\n",
    "#         self.metrics['test_acc'] = trainer.logger.metrics['test_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d553c30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional.classification import multiclass_confusion_matrix\n",
    "\n",
    "def cmat_acc(y_hat, y, num_classes):\n",
    "    y_pred = torch.argmax(y_hat, dim=1)\n",
    "    cmat = multiclass_confusion_matrix(y_pred, y, num_classes)\n",
    "    acc_cmat = cmat.diag().sum() / cmat.sum()\n",
    "    return acc_cmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30910d8dbfaa0aa8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-07-10T12:37:24.440539Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Setting up data module for iteration 1 #####\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/group/coganlab/zms14/miniconda3/envs/micro_decode/lib/python3.11/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/hpc/group/coganlab/zms14/miniconda3/envs/micro_decode/lib/python3.11/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /hpc/group/coganlab/zms14/miniconda3/envs/micro_deco ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/hpc/group/coganlab/zms14/miniconda3/envs/micro_decode/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "Restoring states from the checkpoint path at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_2166/checkpoints/epoch=98-step=99.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': tensor(0.0225), 'train_acc': tensor(0.9995), 'val_loss': tensor(2.9626), 'val_acc': tensor(0.3571)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_2166/checkpoints/epoch=98-step=99.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.4166666567325592\n",
      "        test_loss            1.662295937538147\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "Restoring states from the checkpoint path at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_2167/checkpoints/epoch=63-step=64.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': tensor(0.0241), 'train_acc': tensor(0.9996), 'val_loss': tensor(2.8486), 'val_acc': tensor(0.4048)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_2167/checkpoints/epoch=63-step=64.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.4166666567325592\n",
      "        test_loss           1.5435501337051392\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "Restoring states from the checkpoint path at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_2168/checkpoints/epoch=95-step=96.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': tensor(0.0290), 'train_acc': tensor(0.9982), 'val_loss': tensor(2.4396), 'val_acc': tensor(0.4524)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_2168/checkpoints/epoch=95-step=96.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.6666666865348816\n",
      "        test_loss            1.094774603843689\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "Restoring states from the checkpoint path at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_2169/checkpoints/epoch=66-step=67.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': tensor(0.0235), 'train_acc': tensor(0.9994), 'val_loss': tensor(2.2534), 'val_acc': tensor(0.4048)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_2169/checkpoints/epoch=66-step=67.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc                   0.25\n",
      "        test_loss            1.85834538936615\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "Restoring states from the checkpoint path at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_2170/checkpoints/epoch=73-step=74.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': tensor(0.0250), 'train_acc': tensor(0.9993), 'val_loss': tensor(4.0255), 'val_acc': tensor(0.3571)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_2170/checkpoints/epoch=73-step=74.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc                    0.5\n",
      "        test_loss           1.4842332601547241\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "Restoring states from the checkpoint path at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_2171/checkpoints/epoch=120-step=121.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': tensor(0.0240), 'train_acc': tensor(0.9990), 'val_loss': tensor(2.8771), 'val_acc': tensor(0.4286)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_2171/checkpoints/epoch=120-step=121.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.4583333432674408\n",
      "        test_loss           1.6716084480285645\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "Restoring states from the checkpoint path at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_2172/checkpoints/epoch=298-step=299.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': tensor(0.0210), 'train_acc': tensor(0.9995), 'val_loss': tensor(1.8797), 'val_acc': tensor(0.5714)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_2172/checkpoints/epoch=298-step=299.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.4583333432674408\n",
      "        test_loss            3.346935272216797\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "Restoring states from the checkpoint path at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_2173/checkpoints/epoch=140-step=141.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': tensor(0.0236), 'train_acc': tensor(0.9991), 'val_loss': tensor(1.8965), 'val_acc': tensor(0.6429)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_2173/checkpoints/epoch=140-step=141.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.3333333432674408\n",
      "        test_loss           2.2339043617248535\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "Restoring states from the checkpoint path at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_2174/checkpoints/epoch=122-step=123.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': tensor(0.0270), 'train_acc': tensor(0.9988), 'val_loss': tensor(2.8683), 'val_acc': tensor(0.4222)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_2174/checkpoints/epoch=122-step=123.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.5714285969734192\n",
      "        test_loss            1.012373685836792\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "Restoring states from the checkpoint path at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_2175/checkpoints/epoch=139-step=140.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': tensor(0.0233), 'train_acc': tensor(0.9995), 'val_loss': tensor(2.2853), 'val_acc': tensor(0.4667)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_2175/checkpoints/epoch=139-step=140.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.4761904776096344\n",
      "        test_loss           1.4111121892929077\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "Restoring states from the checkpoint path at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_2176/checkpoints/epoch=82-step=83.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': tensor(0.0239), 'train_acc': tensor(0.9989), 'val_loss': tensor(2.2239), 'val_acc': tensor(0.4889)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_2176/checkpoints/epoch=82-step=83.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.4285714328289032\n",
      "        test_loss           1.6891577243804932\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "Restoring states from the checkpoint path at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_2177/checkpoints/epoch=342-step=343.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': tensor(0.0226), 'train_acc': tensor(0.9991), 'val_loss': tensor(2.9493), 'val_acc': tensor(0.4222)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_2177/checkpoints/epoch=342-step=343.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.7142857313156128\n",
      "        test_loss           1.0994298458099365\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "Restoring states from the checkpoint path at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_2178/checkpoints/epoch=92-step=93.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': tensor(0.0225), 'train_acc': tensor(0.9996), 'val_loss': tensor(2.4630), 'val_acc': tensor(0.4222)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_2178/checkpoints/epoch=92-step=93.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.2857142984867096\n",
      "        test_loss            2.181239604949951\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "Restoring states from the checkpoint path at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_2179/checkpoints/epoch=136-step=137.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': tensor(0.0246), 'train_acc': tensor(0.9985), 'val_loss': tensor(2.8388), 'val_acc': tensor(0.4444)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_2179/checkpoints/epoch=136-step=137.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.4761904776096344\n",
      "        test_loss           1.2276369333267212\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "Restoring states from the checkpoint path at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_2180/checkpoints/epoch=92-step=93.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': tensor(0.0324), 'train_acc': tensor(0.9976), 'val_loss': tensor(2.3529), 'val_acc': tensor(0.4444)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_2180/checkpoints/epoch=92-step=93.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.6190476417541504\n",
      "        test_loss            1.077764630317688\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "Restoring states from the checkpoint path at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_2181/checkpoints/epoch=148-step=149.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': tensor(0.0221), 'train_acc': tensor(0.9991), 'val_loss': tensor(1.9301), 'val_acc': tensor(0.4889)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_2181/checkpoints/epoch=148-step=149.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc             0.523809552192688\n",
      "        test_loss           1.3918503522872925\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "Restoring states from the checkpoint path at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_2182/checkpoints/epoch=162-step=163.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': tensor(0.0237), 'train_acc': tensor(0.9994), 'val_loss': tensor(3.5698), 'val_acc': tensor(0.4000)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_2182/checkpoints/epoch=162-step=163.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.4285714328289032\n",
      "        test_loss           2.0612735748291016\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "Restoring states from the checkpoint path at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_2183/checkpoints/epoch=216-step=217.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': tensor(0.0238), 'train_acc': tensor(0.9990), 'val_loss': tensor(2.0558), 'val_acc': tensor(0.5111)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_2183/checkpoints/epoch=216-step=217.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.2380952388048172\n",
      "        test_loss           2.4368979930877686\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "Restoring states from the checkpoint path at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_2184/checkpoints/epoch=96-step=97.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': tensor(0.0208), 'train_acc': tensor(0.9994), 'val_loss': tensor(2.9041), 'val_acc': tensor(0.3556)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_2184/checkpoints/epoch=96-step=97.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.6190476417541504\n",
      "        test_loss           1.0035786628723145\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "Restoring states from the checkpoint path at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_2185/checkpoints/epoch=310-step=311.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': tensor(0.0244), 'train_acc': tensor(0.9993), 'val_loss': tensor(2.3134), 'val_acc': tensor(0.5556)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_2185/checkpoints/epoch=310-step=311.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.4761904776096344\n",
      "        test_loss           1.9801785945892334\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "0.46785718\n",
      "[[tensor(0.4167), tensor(0.4167), tensor(0.6667), tensor(0.2500), tensor(0.5000), tensor(0.4583), tensor(0.4583), tensor(0.3333), tensor(0.5714), tensor(0.4762), tensor(0.4286), tensor(0.7143), tensor(0.2857), tensor(0.4762), tensor(0.6190), tensor(0.5238), tensor(0.4286), tensor(0.2381), tensor(0.6190), tensor(0.4762)]]\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "n_iters = 1\n",
    "iter_accs = []\n",
    "for i in range(n_iters):\n",
    "    print(f'##### Setting up data module for iteration {i+1} #####')\n",
    "    dm.setup()\n",
    "    \n",
    "    fold_accs = []\n",
    "    # y_pred_all = []\n",
    "    # y_test_all = []\n",
    "    for fold in range(n_folds):\n",
    "        # if fold > 1:\n",
    "        #     break\n",
    "        dm.set_fold(fold)\n",
    "        # print(dm.current_fold)\n",
    "        \n",
    "        # instantiate the model\n",
    "        in_channels = dm.get_data_shape()[-1]\n",
    "        # print(in_channels)\n",
    "        # model = CNNTransformer(in_channels, num_classes, d_model, kernel_size, stride, padding,\n",
    "        #                        n_head, num_layers, dim_fc, cnn_dropout, tform_dropout, learning_rate,\n",
    "        #                        warmup, max_steps, l2_reg, activation=activ)\n",
    "        # model = TCN_classifier(in_channels, num_classes, dim_fc, kernel_size, stride, padding,\n",
    "        #                            cnn_dropout, learning_rate, l2_reg, activation=activ)\n",
    "        # model = TemporalConvRNN(in_channels, n_filters, num_classes, hidden_size, n_layers,\n",
    "                                # kernel_size, dim_fc, stride, padding, cnn_dropout,\n",
    "                                # rnn_dropout, learning_rate, l2_reg, activation=activ,\n",
    "                                # decay_iters=max_epochs)\n",
    "        model = Seq2SeqRNN(in_channels, n_filters, hidden_size, num_classes, n_enc_layers,\n",
    "                           n_dec_layers, kernel_size, stride, padding, cnn_dropout, rnn_dropout, model_type,\n",
    "                           learning_rate, l2_reg, activation=activ, decay_iters=max_epochs)\n",
    "        \n",
    "        # model.current_fold = fold\n",
    "        callbacks = [\n",
    "            # ModelCheckpoint(monitor='val_loss', mode='min'),\n",
    "            ModelCheckpoint(monitor='val_acc', mode='max'),\n",
    "            # EarlyStopping(monitor='val_loss', patience=es_pat),\n",
    "            LearningRateMonitor(logging_interval='epoch'),\n",
    "            ]\n",
    "        trainer = L.Trainer(default_root_dir=log_dir,\n",
    "                            max_epochs=max_epochs,\n",
    "                            # max_steps=max_steps,\n",
    "                            gradient_clip_val=gclip_val,\n",
    "                            accelerator='auto',\n",
    "                            callbacks=callbacks,\n",
    "                            logger=True,\n",
    "                            enable_model_summary=False,\n",
    "                            enable_progress_bar=False,\n",
    "                           )\n",
    "        # # trainer.fit(model, dm)\n",
    "        trainer.fit(model=model, train_dataloaders=dm.train_dataloader(), val_dataloaders=dm.val_dataloader())\n",
    "        print(trainer.logged_metrics)\n",
    "        # print(trainer.callback_metrics)\n",
    "        # print the training metrics from the best model checkpoint\n",
    "        # print(f'Fold {fold} best model metrics:')\n",
    "        # print(trainer.checkpoint_callback.best_model_score)\n",
    "\n",
    "\n",
    "        # trainer.test(model, dm)\n",
    "        # model = CNNTransformer.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
    "        trainer.test(model=model, dataloaders=dm.test_dataloader(), ckpt_path='best')\n",
    "        # trainer.test(dataloaders=dm.test_dataloader(), ckpt_path='best')\n",
    "\n",
    "        # test_pred = model(dm.test_dataloader().dataset.tensors[0])\n",
    "        # test_pred = trainer.predict(model, dm.test_dataloader(), ckpt_path='best)[0]\n",
    "        # test_pred = torch.argmax(test_pred, dim=1)\n",
    "        # print(test_pred)\n",
    "        # y_pred_all.extend(test_pred)\n",
    "        # y_test_all.extend(dm.test_dataloader().dataset.tensors[1])\n",
    "        \n",
    "        fold_accs.append(trainer.logged_metrics['test_acc'])\n",
    "    \n",
    "        # save loss information\n",
    "        # loss_dict = trainer.logger.metrics\n",
    "        # loss_dict['fold'] = fold\n",
    "        # loss_dict['model'] = model\n",
    "    # acc = cmat_acc(torch.stack(y_pred_all), torch.stack(y_test_all), num_classes)\n",
    "    # print(acc)\n",
    "    # iter_accs.append(acc)\n",
    "    # print(f'Averaged accuracy: {sum(fold_accs) / len(fold_accs)}')\n",
    "    iter_accs.append(fold_accs)\n",
    "    with open(os.path.join(log_dir, f'accs/{context_prefix}/{context_prefix}_seq2seq_rnn_accs_iter{i+1}.csv'), 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(iter_accs)\n",
    "    print(np.mean(fold_accs))\n",
    "# print(sum(iter_accs) / len(iter_accs), iter_accs)\n",
    "print(iter_accs)\n",
    "with open(os.path.join(log_dir, f'accs/{context_prefix}/{context_prefix}_seq2seq_rnn_accs.csv'), 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(iter_accs)\n",
    "np.save(os.path.join(log_dir, f'accs/{context_prefix}/{context_prefix}_seq2seq_rnn_accs.npy'), np.array(iter_accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e334142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 20)\n",
      "[0.46785718]\n",
      "0.46785718\n"
     ]
    }
   ],
   "source": [
    "iter_accs = np.load(os.path.join(log_dir, f'accs/{context_prefix}/{context_prefix}_seq2seq_rnn_accs.npy'))\n",
    "print(iter_accs.shape)\n",
    "print(iter_accs.mean(axis=1))\n",
    "print(iter_accs.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a9b87d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAmtUlEQVR4nO3df1Tc9Z3v8dcAYSbSMrkGnfwQEKu4BMraDIcIOand1bIXe7xMWCpHTxPtJo2sti6y9rSQc0zl7Al7ujZNuisY1qTZtNbDuoFRu3Tt7N7diIvriVzsoUl2EzeuQ+MggusQjQED3/tHTmY7DkOYCfDJDM/HOd+j8/5+vjPvEZl58fn+slmWZQkAAMCQFNMNAACAxY0wAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMCoNNMNzMbU1JTeeecdffazn5XNZjPdDgAAmAXLsnTmzBmtWrVKKSnR5z8SIoy88847ys7ONt0GAACIw+DgoK677rqo6xMijHz2s5+VdOHNZGZmGu4GAADMxtjYmLKzs0Pf49EkRBi5uGsmMzOTMAIAQIK51CEWHMAKAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMADDG6/WqtLRUGRkZKi0tldfrNd0SAAMIIwCM8Hq92rhxo44cOaKzZ8/qyJEjqq6uJpAAi1BC3JsGmGvnzp2T3+833cai9thjj0XULMvSjh07tGbNGgMd4aKcnBw5HA7TbWARIYxgUfL7/dq2bZvpNha1o0ePTlv/9a9/zc/GsPb2duXn55tuA4sIYQSLUk5Ojtrb2023sajV1NRoYGAgol5UVMTPxrCcnBzTLWCRIYxgUXI4HPzlZ1hzc7Oqq6tlWVaoZrPZ1NzczM8GWGTiOoC1tbVVeXl5cjgccrvd6unpiTr2/vvvl81mi1gKCwvjbhpA4vN4POrs7FRxcbFSUlJUXFysrq4uVVVVmW4NwAKLOYx0dHSovr5e27dvV39/vzZs2KDKysqoBwPu2bNHgUAgtAwODurqq6/WV7/61ctuHkBi83g8eu6557RhwwY999xzBBFgkYo5jOzatUtbtmzR1q1bVVBQoN27dys7O1ttbW3Tjnc6nVqxYkVoef311/Xf//3f+vrXv37ZzQMAgMQXUxiZmJhQX1+fKioqwuoVFRXq7e2d1XPs27dPd9xxh3Jzc6OOGR8f19jYWNgCAACSU0xhZGRkRJOTk3K5XGF1l8uloaGhS24fCAT0i1/8Qlu3bp1xXEtLi5xOZ2jJzs6OpU0AAJBA4jqA1WazhT22LCuiNp0DBw5o2bJl8ng8M45rbGxUMBgMLYODg/G0CQAAEkBMp/ZmZWUpNTU1YhZkeHg4Yrbk0yzL0v79+7Vp0yalp6fPONZut8tut8fSGgAASFAxzYykp6fL7XbL5/OF1X0+n8rLy2fc9vDhw3rzzTe1ZcuW2LsEAABJK+aLnjU0NGjTpk0qKSlRWVmZ2tvb5ff7VVdXJ+nCLpbTp0/r4MGDYdvt27dP69atU1FR0dx0DgAAkkLMYaS2tlajo6Nqbm5WIBBQUVGRuru7Q2fHBAKBiGuOBINBHTp0SHv27JmbrgEAQNKI63LwDz74oB588MFp1x04cCCi5nQ6dfbs2XheCgAAJLm4zqYBAACYK4QRAABgFGEEAAAYRRgBAABGEUYAAIBRhBEAAGAUYQSAMV6vVzU1Nerp6VFNTY28Xq/plgAYQBgBYITX69XGjRs1MDCgqakpDQwMqLq6mkACLEKEEQBG7Ny5M6JmWZZaWloMdAPAJMIIACOOHj0aUx1A8iKMADCisLAwpjqA5EUYAWBEU1OTbDZbWM1ms6mpqclQRwBMIYwAMMLj8aizs1PFxcVKSUlRcXGxurq6VFVVZbo1AAssrrv2AsBc8Hg8WrNmjbZt26b29nbl5+ebbgmAAcyMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAmFder1elpaXKyMhQaWmpvF5v2Lqamhr19PSopqYmbB2AxcNmWZZluolLGRsbk9PpVDAYVGZmpul2AMyS1+vVxo0bw2o2m02dnZ2SFHWdx+NZqBYBzKPZfn8TRgDMm9LSUh05cmTaumVZUde99tprC9EegHk22+/vtAXsCcAic/To0aj1aH8HRdsGQPLimBEA86awsDBqfaZ1ABYXwgiAedPU1CSbzRZWs9lsampqmnEdgMWFMAJg3ng8HnV2doadTdPV1aWqqqrQuuLiYqWkpKi4uDi0DsDiwgGsAIw6ceKEtm3bpvb2duXn55tuB8Acmu33d1wzI62trcrLy5PD4ZDb7VZPT8+M48fHx7V9+3bl5ubKbrfrc5/7nPbv3x/PSwMAgCQT89k0HR0dqq+vV2trq9avX6+9e/eqsrJSx44dU05OzrTb3H333Xr33Xe1b98+3XjjjRoeHtb58+cvu3kAAJD4Yg4ju3bt0pYtW7R161ZJ0u7du/XSSy+pra1NLS0tEeP/4R/+QYcPH9apU6d09dVXS5Kuv/76y+saAAAkjZh200xMTKivr08VFRVh9YqKCvX29k67zQsvvKCSkhJ9//vf1+rVq5Wfn69HH31UH3/8cdTXGR8f19jYWNgCAACSU0wzIyMjI5qcnJTL5Qqru1wuDQ0NTbvNqVOn9Morr8jhcKirq0sjIyN68MEH9f7770c9bqSlpUWPP/54LK0BAIAEFdcBrJ++NoBlWRG1i6ampmSz2fTMM8+otLRUd955p3bt2qUDBw5EnR1pbGxUMBgMLYODg/G0CQAAEkBMMyNZWVlKTU2NmAUZHh6OmC25aOXKlVq9erWcTmeoVlBQIMuy9Jvf/EY33XRTxDZ2u112uz2W1gAAQIKKaWYkPT1dbrdbPp8vrO7z+VReXj7tNuvXr9c777yjDz/8MFQ7ceKEUlJSdN1118XRMgAASCYx76ZpaGjQ008/rf379+v48eN65JFH5Pf7VVdXJ+nCLpbNmzeHxt97771avny5vv71r+vYsWN6+eWX9e1vf1t/9Ed/pKVLl87dOwEAAAkp5lN7a2trNTo6qubmZgUCARUVFam7u1u5ubmSpEAgIL/fHxr/mc98Rj6fT9/61rdUUlKi5cuX6+6779af/dmfzd27AAAACYvLwQMwisvBA8lrXi8HDwAAMFcIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAIzxer2qqalRT0+Pampq5PV6TbcEwADCCAAjvF6vNm7cqIGBAU1NTWlgYEDV1dUEEmARIowAMGLnzp0RNcuy1NLSYqAbACYRRgAYcfTo0ZjqAJIXYQSAEYWFhTHVASQvwggAI5qammSz2cJqNptNTU1NhjoCYAphBIARHo9HnZ2dKi4uVkpKioqLi9XV1aWqqirTrQFYYDHftRcA5orH49GaNWu4UR6wyDEzAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjuTbOA3n33XQWDQdNtAFeUt99+O+yfAC5wOp1yuVym21gQNsuyLNNNXMrY2JicTqeCwaAyMzNNtxOXd999V1/btFmfTIybbgUAkACWpNv1058cTOhAMtvvb2ZGFkgwGNQnE+P6+IbbNOVwmm4HAHAFSzkXlE4dVjAYTOgwMluEkQU25XBqKiPLdBsAAFwxCCMAjPngZJ+GXntR50ZOy5G1WivW3aVlN7lNtwVggXE2DQAjPjjZp1PP/0hnh97S1PkJnR16S6ee/0t9cLLPdGsAFhhhBIARQ6+9OE3V0tBrP1/wXgCYRRgBYMS5kdPT10enrwNIXoQRAEY4slZPX18+fR1A8iKMADBixbq7JNk+VbVpxa13mWgHgEGEEQBGLLvJrRuqvqWrVtyglCV2XbXiBt3geVjLblxrujUAC4xTewEYs+wmN6fyAmBmBAAAmEUYAQAARhFGAACAUXGFkdbWVuXl5cnhcMjtdqunpyfq2H/5l3+RzWaLWP793/897qYBAEDyiPkA1o6ODtXX16u1tVXr16/X3r17VVlZqWPHjiknJyfqdv/xH/8Rdvvga665Jr6OASQN7k0DQIpjZmTXrl3asmWLtm7dqoKCAu3evVvZ2dlqa2ubcbtrr71WK1asCC2pqalxNw0g8XFvGgAXxRRGJiYm1NfXp4qKirB6RUWFent7Z9z2C1/4glauXKnbb79d//zP/zzj2PHxcY2NjYUtAJIL96YBcFFMYWRkZESTk5NyuVxhdZfLpaGhoWm3Wblypdrb23Xo0CF1dnbq5ptv1u23366XX3456uu0tLTI6XSGluzs7FjaBJAAuDcNgIviuuiZzRZ+CWfLsiJqF9188826+eabQ4/Lyso0ODioJ554Ql/84hen3aaxsVENDQ2hx2NjYwQSIMk4slbr7NBbkXXuTQMsOjHNjGRlZSk1NTViFmR4eDhitmQmt956q06ePBl1vd1uV2ZmZtgCILlwbxoAF8UURtLT0+V2u+Xz+cLqPp9P5eXls36e/v5+rVy5MpaXBpBkuDcNgIti3k3T0NCgTZs2qaSkRGVlZWpvb5ff71ddXZ2kC7tYTp8+rYMHD0qSdu/ereuvv16FhYWamJjQT3/6Ux06dEiHDh2a23cCIOFwbxoAUhxhpLa2VqOjo2publYgEFBRUZG6u7uVm5srSQoEAvL7/aHxExMTevTRR3X69GktXbpUhYWF+vu//3vdeeedc/cuAABAwrJZlmWZbuJSxsbG5HQ6FQwGE/b4kRMnTmjbtm36aM3/0VRGlul2AABXsJSPRpRx7AW1t7crPz/fdDtxm+33N/emAQAARhFGAACAUXFdZwQAZmum+8/Euw5AcmFmBMC8men+M/GuA5B8mBkBMG9mvv/MdMfOX3odsyNA8iGMAJg3M95/JsqJfJdcByDpsJsGwLxxZE1/nxnH8tVxrwOQfAgjAObNTPefiXcdgOTDbpoFlvLxB6ZbABbM1atyZfvf92no//1fffz+kJZevUIr1t6u/7UyR5LiW/fRiMm3BCyIxfZdQRhZYEvfetl0C8CCypB0XUGepLwLhY9PScdOXdY6AMmFMLLAPs77oqaWLjPdBgDgCpby8QeL6o9XwsgCm1q6jHvTYFHhwmYALoUDWAHMGy5sBmA2mBkBMG/ivegZsyPA4kIYATBv4r7oGYBFhd00AOYNFzYDMBuEEQDzhgubAZgNdtMAmDfLbnLrhqpvaei1n+vc6Gk5lq/Wilvv0rIb10rSjOsALB6EEQDzatlN7qgHpM60DsDiwW4aAABgFGEEAAAYRRgBAABGEUYAAIBRhBEAAGAUYQQAABhFGAEAAEZxnREAc+qDk30aeu1FnRs5LUfWaq1Yd9esryVyOdsCSFzMjACYMx+c7NOp53+ks0Nvaer8hM4OvaVTz/+lPjjZN6/bAkhshBEAc2botRenqVoaeu3n87otgMRGGAEwZ86NnJ6+Pjp9fa62BZDYCCMA5owja/X09eXT1+dqWwCJjQNYAcyZFevu0qnn/1KSFVY/f+5DvbH7GxEHpf72Aatpn1k2zTPatOLWu+a9bwBmMTMCYM4su8mtG6q+patW3KCUJXbZl7kkSRMfDEcclPrpA1YnPhiWJNmXuZSyxK6rVtygGzwPa9mNa02+JQALgJmRBZZyLmi6BWBeXb0qV1dvfEiSdOzQ7mlGWHr3Va+sT82eXJSWbtfn79n5P4WPRua+SeAKt9i+KwgjC8TpdGpJul06ddh0K8CCiXZQ6scjv4m6zccjv1HGsRfmqyUgYSxJt8vpdJpuY0EQRhaIy+XST39yUMHg4kq7WNxqamo0MDAQUS8qKpJlWVHXtbe3L0R7wBXN6XTK5XKZbmNB2CzLmn6u9AoyNjYmp9OpYDCozMxM0+0AmCWv16vq6mr99seMzWZTV1eXLMuKuq6qqspEuwDm2Gy/vzmAFcC88Xg86uzsVGlpqTIyMlRaWhoKGxfXFRcXKyUlRcXFxQQRYJFiZgSAUSdOnNC2bdvU3t6u/Px80+0AmEPzOjPS2tqqvLw8ORwOud1u9fT0zGq7f/3Xf1VaWppuueWWeF4WAAAkoZjDSEdHh+rr67V9+3b19/drw4YNqqyslN/vn3G7YDCozZs36/bbb4+7WQAAkHxiDiO7du3Sli1btHXrVhUUFGj37t3Kzs5WW1vbjNs98MADuvfee1VWVhZ3swAAIPnEFEYmJibU19enioqKsHpFRYV6e3ujbvfjH/9Y//mf/6kdO3bM6nXGx8c1NjYWtgAAgOQUUxgZGRnR5ORkxHnPLpdLQ0ND025z8uRJffe739UzzzyjtLTZXdakpaVFTqcztGRnZ8fSJgAASCBxHcBqs9nCHluWFVGTpMnJSd177716/PHHYzpKvrGxUcFgMLQMDg7G0yYAAEgAMV2BNSsrS6mpqRGzIMPDw9NeJe7MmTN6/fXX1d/fr29+85uSpKmpKVmWpbS0NP3yl7/U7//+70dsZ7fbZbfbY2kNAAAkqJhmRtLT0+V2u+Xz+cLqPp9P5eXlEeMzMzM1MDCgN954I7TU1dXp5ptv1htvvKF169ZdXvcAACDhxXxvmoaGBm3atEklJSUqKytTe3u7/H6/6urqJF3YxXL69GkdPHhQKSkpKioqCtv+2muvlcPhiKgDAIDFKeYwUltbq9HRUTU3NysQCKioqEjd3d3Kzc2VJAUCgUtecwQAAOAiLgcPwCguBw8kL26UBwAAEgJhBAAAGEUYAQAARhFGAACAUYQRAABgFGEEAAAYRRgBAABGEUYAAIBRhBEAAGAUYQQAABhFGAEAAEYRRgAAgFGEEQAAYBRhBAAAGEUYAQAARhFGAACAUYQRAABgFGEEAAAYRRgBAABGEUYAAIBRhBEAAGAUYQQAABhFGAEAAEYRRgAY4/V6VVNTo56eHtXU1Mjr9ZpuCYABhBEARni9Xm3cuFEDAwOamprSwMCAqqurCSTAIkQYAWDEzp07I2qWZamlpcVANwBMIowAMOLo0aMx1QEkL8IIACMKCwtjqgNIXoQRAEY0NTXJZrOF1Ww2m5qamgx1BMAUwggAIzwejzo7O1VcXKyUlBQVFxerq6tLVVVVplsDsMDSTDcAYPHyeDxas2aNtm3bpvb2duXn55tuCYABzIwAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMCquMNLa2qq8vDw5HA653W719PREHfvKK69o/fr1Wr58uZYuXarf+Z3f0Q9/+MO4GwYAAMkl5ouedXR0qL6+Xq2trVq/fr327t2ryspKHTt2TDk5ORHjMzIy9M1vflPFxcXKyMjQK6+8ogceeEAZGRnatm3bnLwJAACQuGyWZVmxbLBu3TqtXbtWbW1toVpBQYE8Hs+sb/1dXV2tjIwM/eQnP5nV+LGxMTmdTgWDQWVmZsbSLoAr3IkTJ7gCK5CkZvv9HdNumomJCfX19amioiKsXlFRod7e3lk9R39/v3p7e3XbbbdFHTM+Pq6xsbGwBQAAJKeYwsjIyIgmJyflcrnC6i6XS0NDQzNue91118lut6ukpEQPPfSQtm7dGnVsS0uLnE5naMnOzo6lTQAAkEDiOoD107f9tiwrovZpPT09ev311/XUU09p9+7devbZZ6OObWxsVDAYDC2Dg4PxtAkAABJATAewZmVlKTU1NWIWZHh4OGK25NPy8vIkSZ///Of17rvv6nvf+57uueeeacfa7XbZ7fZYWgMAAAkqppmR9PR0ud1u+Xy+sLrP51N5efmsn8eyLI2Pj8fy0gAAIEnFvJumoaFBTz/9tPbv36/jx4/rkUcekd/vV11dnaQLu1g2b94cGv/kk0/qxRdf1MmTJ3Xy5En9+Mc/1hNPPKGvfe1rc/cuACQkr9ermpoa9fT0qKamRl6v13RLAAyI+TojtbW1Gh0dVXNzswKBgIqKitTd3a3c3FxJUiAQkN/vD42fmppSY2Oj3nrrLaWlpelzn/uc/vzP/1wPPPDA3L0LAAnH6/Vq48aNoccDAwOqrq5WZ2enPB6PucYALLiYrzNiAtcZAZJPaWmpjhw5Mm39tddeM9ARgLk2L9cZAYC5cvTo0ZjqAJIXYQSAEYWFhTHVASQvwggAI5qamiKuT2Sz2dTU1GSoIwCmEEYAGOHxeNTZ2ani4mKlpKSouLhYXV1dqqqqMt0agAUW89k0ADBXPB6P1qxZw43ygEWOmREAAGAUYQQAABhFGAEAAEYRRgAAgFGEEQAAYBRhBAAAGEUYAQAARhFGAACAUYQRAABgFGEEAAAYRRgBsGC8Xq9KS0uVkZGh0tJSeb1e0y0BuAJwbxoAC8Lr9Wrjxo2hx0eOHFF1dbX+6q/+ymBXAK4EzIwAWBA7d+6MqFmWpb179xroBsCVhDACYEEcPXp02vqbb765wJ0AuNIQRgAsiMLCwmnrN9544wJ3AuBKQxgBsCCamppks9nCajabTQ888IChjgBcKQgjABaEx+NRZ2dn2Nk03/nOd/TUU0+pp6dHNTU1nF0DLFI2y7Is001cytjYmJxOp4LBoDIzM023A2AOfPrsGunCTElnZ6c8Ho+ZpgDMqdl+f3NqLxalc+fOye/3m25jUXvsscciapZlaceOHVqzZo2BjnBRTk6OHA6H6TawiBBGsCj5/X5t27bNdBuLWrSza37961/zszGsvb1d+fn5ptvAIkIYwaKUk5Oj9vZ2020sajU1NRoYGIioFxUV8bMxLCcnx3QLWGQII1iUHA4Hf/kZ1tzcrOrqav32YWs2m03Nzc38bIBFhrNpABgx3dk1XV1dqqqqMt0agAXG2TQAAGBezPb7m5kRAABgFGEEAAAYRRgBAABGEUYAAIBRhBEAAGAUYQQAABhFGAEAAEYRRgAAgFGEEQAAYBRhBAAAGBVXGGltbVVeXp4cDofcbrd6enqiju3s7NSXv/xlXXPNNcrMzFRZWZleeumluBsGAADJJeYw0tHRofr6em3fvl39/f3asGGDKisr5ff7px3/8ssv68tf/rK6u7vV19en3/u939Ndd92l/v7+y24eAAAkvphvlLdu3TqtXbtWbW1toVpBQYE8Ho9aWlpm9RyFhYWqra3VY489Nqvx3CgPAIDEMy83ypuYmFBfX58qKirC6hUVFert7Z3Vc0xNTenMmTO6+uqro44ZHx/X2NhY2AIAAJJTTGFkZGREk5OTcrlcYXWXy6WhoaFZPccPfvADffTRR7r77rujjmlpaZHT6Qwt2dnZsbQJAAASSFwHsNpstrDHlmVF1Kbz7LPP6nvf+546Ojp07bXXRh3X2NioYDAYWgYHB+NpEwAAJIC0WAZnZWUpNTU1YhZkeHg4Yrbk0zo6OrRlyxY999xzuuOOO2Yca7fbZbfbY2kNAAAkqJhmRtLT0+V2u+Xz+cLqPp9P5eXlUbd79tlndf/99+tnP/uZvvKVr8TXKQAASEoxzYxIUkNDgzZt2qSSkhKVlZWpvb1dfr9fdXV1ki7sYjl9+rQOHjwo6UIQ2bx5s/bs2aNbb701NKuydOlSOZ3OOXwrAAAgEcUcRmprazU6Oqrm5mYFAgEVFRWpu7tbubm5kqRAIBB2zZG9e/fq/Pnzeuihh/TQQw+F6vfdd58OHDhw+e8AAAAktJivM2IC1xkBACDxzMt1RgAAAOYaYQQAABhFGAEAAEYRRgAAgFGEEQAAYBRhBAAAGEUYAQAARhFGAACAUYQRAABgFGEEAAAYRRgBAABGEUYAAIBRhBEAAGAUYQQAABhFGAEAAEYRRgAAgFGEEQAAYBRhBAAAGEUYAQAARhFGAACAUYQRAABgFGEEAAAYRRgBAABGEUYAAIBRhBEAAGAUYQQAABhFGAEAAEYRRgAAgFGEEQAAYBRhBAAAGEUYAQAARhFGAACAUYQRAABgFGEEAAAYRRgBAABGpZluIBYTExOamJiIqKekpCgtLS1sXDQ2m01LliyJa+wnn3wiy7IWdKwkpaenxzX2/PnzmpqampOxS5Yskc1mm9exk5OTmpycnJOxaWlpSklJuWLGTk1N6fz581HHpqamKjU19YoZa1mWPvnkkzkZ+9u/n/M1Vpr5d5nPiOnH8hnBZ8RCfEbMRkKFkR/84AdyOBwR9Ztuukn33ntv6PETTzwR9T9Sbm6u7r///tDjPXv26OzZs9OOXbVqlb7xjW+EHj/55JMKBoPTjr3mmmv04IMPhh7/9V//td57771pxzqdTtXX14ceHzhwQO+88860Y6+66ip9+9vfDj1+5pln9Pbbb087dsmSJWpqago9/tu//VudPHly2rGStGPHjtC/d3V16dixY1HHNjY2hj6Yfv7zn+tXv/pV1LGPPvqoMjIyJEkvvfSSXn/99ahj/+RP/kTLli2TJP3TP/2TXn311ahj//iP/1jXXnutJKmnp0eHDx+OOnbr1q1avXq1JOnf/u3f9I//+I9Rx9533326/vrrJUl9fX36xS9+EXXsPffco/z8fEnSwMCAnn/++ahja2pqVFhYKEk6fvy4/u7v/i7q2KqqKt1yyy2SpDfffFPPPvts1LGVlZUqLS2VJPn9fv3N3/xN1LF33HGH1q9fL0kKBAJ6+umno4697bbb9KUvfUmS9N5776mtrS3q2LKyMlVUVEiSgsGg9uzZE3VsSUmJvvKVr0iSzp49qyeeeCLq2N/93d+Vx+ORdOFLtaWlJerYNWvW6Ktf/Wro8Uxj+Yy4gM+I/8FnxAUL8RkxG+ymAQAARtmsmebzomhtbdVf/MVfKBAIqLCwULt379aGDRumHRsIBPSnf/qn6uvr08mTJ/Xwww9r9+7dMb3e2NiYnE6n3nvvPWVmZkasZwp2+rFMwTIFy26a2MfyGRHfWD4jLm/slfB7Px+fERe/v4PB4LTf3xfFvJumo6ND9fX1am1t1fr167V3715VVlbq2LFjysnJiRg/Pj6ua665Rtu3b9cPf/jDWF8uTHp6etgvx0zjYnnO2frtD4dEGPvbH76JMDaWfYyJNjYlJWXW/69dCWNtNltCjZXm7/eez4grZ+yV8LvMZ8QFsf5+XvL5Yp0ZWbdundauXRu2r6igoEAej2fGfbaS9KUvfUm33HJL3DMjl0pWAADgyjHb7++YjhmZmJhQX19fxEEpFRUV6u3tja9TAACwqMW0m2ZkZESTk5NyuVxhdZfLpaGhoTlranx8XOPj46HHY2Njc/bcAADgyhLX2TQXDxC6yLKsiNrlaGlpkdPpDC3Z2dlz9twAAODKElMYycrKUmpqasQsyPDwcMRsyeVobGxUMBgMLYODg3P23AAA4MoSUxhJT0+X2+2Wz+cLq/t8PpWXl89ZU3a7XZmZmWELAABITjGf2tvQ0KBNmzappKREZWVlam9vl9/vV11dnaQLsxqnT5/WwYMHQ9u88cYbkqQPP/xQ7733nt544w2lp6drzZo1c/MuAABAwoo5jNTW1mp0dFTNzc0KBAIqKipSd3e3cnNzJV24yJnf7w/b5gtf+ELo3/v6+vSzn/1Mubm5+q//+q/L6x4AACS8uK7AutC4zggAAIlnXq4zAgAAMNcIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMCquMNLa2qq8vDw5HA653W719PTMOP7w4cNyu91yOBy64YYb9NRTT8XVLAAASD4xh5GOjg7V19dr+/bt6u/v14YNG1RZWSm/3z/t+Lfeekt33nmnNmzYoP7+fjU1Nenhhx/WoUOHLrt5AACQ+GyWZVmxbLBu3TqtXbtWbW1toVpBQYE8Ho9aWloixn/nO9/RCy+8oOPHj4dqdXV1+tWvfqVXX311Vq85NjYmp9OpYDCozMzMWNoFAACGzPb7Oy2WJ52YmFBfX5+++93vhtUrKirU29s77TavvvqqKioqwmp/8Ad/oH379umTTz7RkiVLIrYZHx/X+Ph46HEwGJR04U0BAIDEcPF7+1LzHjGFkZGREU1OTsrlcoXVXS6XhoaGpt1maGho2vHnz5/XyMiIVq5cGbFNS0uLHn/88Yh6dnZ2LO0CAIArwJkzZ+R0OqOujymMXGSz2cIeW5YVUbvU+OnqFzU2NqqhoSH0eGpqSu+//76WL18+4+sASDxjY2PKzs7W4OAgu2GBJGNZls6cOaNVq1bNOC6mMJKVlaXU1NSIWZDh4eGI2Y+LVqxYMe34tLQ0LV++fNpt7Ha77HZ7WG3ZsmWxtAogwWRmZhJGgCQ004zIRTGdTZOeni632y2fzxdW9/l8Ki8vn3absrKyiPG//OUvVVJSMu3xIgAAYHGJ+dTehoYGPf3009q/f7+OHz+uRx55RH6/X3V1dZIu7GLZvHlzaHxdXZ3efvttNTQ06Pjx49q/f7/27dunRx99dO7eBQAASFgxHzNSW1ur0dFRNTc3KxAIqKioSN3d3crNzZUkBQKBsGuO5OXlqbu7W4888oiefPJJrVq1Sj/60Y/0h3/4h3P3LgAkLLvdrh07dkTsmgWweMR8nREAAIC5xL1pAACAUYQRAABgFGEEAAAYRRgBAABGEUYAGNPa2qq8vDw5HA653W719PSYbgmAAYQRAEZ0dHSovr5e27dvV39/vzZs2KDKysqwSwMAWBw4tReAEevWrdPatWvV1tYWqhUUFMjj8ailpcVgZwAWGjMjABbcxMSE+vr6VFFREVavqKhQb2+voa4AmEIYAbDgRkZGNDk5GXGDTZfLFXFjTQDJjzACwBibzRb22LKsiBqA5EcYAbDgsrKylJqaGjELMjw8HDFbAiD5EUYALLj09HS53W75fL6wus/nU3l5uaGuAJgS8117AWAuNDQ0aNOmTSopKVFZWZna29vl9/tVV1dnujUAC4wwAsCI2tpajY6Oqrm5WYFAQEVFReru7lZubq7p1gAsMK4zAgAAjOKYEQAAYBRhBAAAGEUYAQAARhFGAACAUYQRAABgFGEEAAAYRRgBAABGEUYAAIBRhBEAAGAUYQQAABhFGAEAAEYRRgAAgFH/H81SrmbVcTm+AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# from torch import tensor\n",
    "# test = [[tensor(0.5000), tensor(0.3636), tensor(0.2727), tensor(0.4545), tensor(0.3182), tensor(0.4545), tensor(0.4091), tensor(0.2273), tensor(0.2727), tensor(0.4091), tensor(0.2727), tensor(0.3182), tensor(0.3333), tensor(0.3333), tensor(0.4762), tensor(0.3333), tensor(0.2857), tensor(0.3810), tensor(0.3810), tensor(0.3810)]]\n",
    "# plt.boxplot(iter_accs.mean(axis=1))\n",
    "# sns.boxplot(data=iter_accs.mean(axis=1))\n",
    "# sns.swarmplot(data=iter_accs.mean(axis=1), color='black')\n",
    "sns.boxplot(data=iter_accs.T)\n",
    "sns.swarmplot(data=iter_accs.T, color='black')\n",
    "plt.axhline(y=1/9, color='gray', linestyle='--')\n",
    "plt.ylim(0, None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc82690e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46785718"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.mean(fold_accs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
