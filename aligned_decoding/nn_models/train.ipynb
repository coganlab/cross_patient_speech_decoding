{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "629c8e9894f680c6",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9de9524454a74a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:36:37.423150Z",
     "start_time": "2024-07-10T12:36:26.252451Z"
    }
   },
   "outputs": [],
   "source": [
    "# %% Imports\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint, LearningRateMonitor\n",
    "from pytorch_lightning.utilities.model_summary import summarize\n",
    "import torch\n",
    "import numpy as np\n",
    "from data_utils.datamodules import SimpleMicroDataModule, AlignedMicroDataModule\n",
    "from models import CNNTransformer, Transformer, TCN_classifier, TemporalConvRNN, Seq2SeqRNN\n",
    "import data_utils.augmentations as augs\n",
    "import csv\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from alignment import alignment_utils as utils\n",
    "from alignment.AlignCCA import AlignCCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae402b0e2a9fc07",
   "metadata": {},
   "source": [
    "# Define data module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a46a71918adb132d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:36:42.704611Z",
     "start_time": "2024-07-10T12:36:37.423150Z"
    }
   },
   "outputs": [],
   "source": [
    "data_filename = os.path.expanduser('~/data/pt_decoding_data_S62.pkl')\n",
    "# data_filename = ('../data/pt_decoding_data_S62.pkl')\n",
    "pt_data = utils.load_pkl(data_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ced55da2478416b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:36:42.715275Z",
     "start_time": "2024-07-10T12:36:42.704611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(144, 200, 111), (144,), (144, 3)]\n",
      "[[(148, 200, 111), (148,), (148, 3)], [(151, 200, 63), (151,), (151, 3)], [(46, 200, 149), (46,), (46, 3)], [(151, 200, 74), (151,), (151, 3)], [(137, 200, 144), (137,), (137, 3)], [(141, 200, 171), (141,), (141, 3)], [(178, 200, 201), (178,), (178, 3)]]\n"
     ]
    }
   ],
   "source": [
    "pt = 'S14'\n",
    "p_ind = 1\n",
    "lab_type = 'phon'\n",
    "algn_type = 'phon_seq'\n",
    "tar_data, pre_data = utils.decoding_data_from_dict(pt_data, pt, p_ind,\n",
    "                                                   lab_type=lab_type,\n",
    "                                                   algn_type=algn_type)\n",
    "print([d.shape for d in tar_data])\n",
    "print([[d.shape for d in p] for p in pre_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b30a66092a23064f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:37:23.778265Z",
     "start_time": "2024-07-10T12:36:42.715275Z"
    }
   },
   "outputs": [],
   "source": [
    "# fold_data_path = '.'\n",
    "\n",
    "fs = 200 # Hz\n",
    "# augmentations = [augs.time_warping, augs.time_masking, augs.time_shifting, augs.noise_jitter, augs.scaling]\n",
    "augmentations = [augs.time_shifting, augs.noise_jitter, augs.scaling]\n",
    "# augmentations = None\n",
    "# data = torch.rand(n_samples, n_timepoints, n_features)\n",
    "# labels = torch.randint(0, 9, (n_samples,))\n",
    "# data = torch.Tensor(all_pt_dict['S14']['X1'])\n",
    "# labels = torch.Tensor(all_pt_dict['S14']['y1']).long() - 1\n",
    "data = torch.Tensor(tar_data[0])\n",
    "labels = torch.Tensor(tar_data[1]).long().unsqueeze(1) - 1\n",
    "align_labels = torch.Tensor(tar_data[2]).long() - 1\n",
    "# pool_data = [(torch.Tensor(p[0]), torch.Tensor(p[1]).long().unsqueeze(1) - 1, torch.Tensor(p[2]).long() - 1) for p in pre_data]\n",
    "pool_data = [(torch.Tensor(p[0]), torch.Tensor(p[2]).long() - 1, torch.Tensor(p[2]).long() - 1) for p in pre_data]  # for seq2seq RNN\n",
    "# data = torch.Tensor(all_pt_dict['S14']['X_collapsed'])\n",
    "# labels = torch.Tensor(all_pt_dict['S14']['y_phon_collapsed']).long() - 1\n",
    "\n",
    "# create the data module\n",
    "batch_size = 5000\n",
    "n_folds = 20\n",
    "val_size = 0.1\n",
    "\n",
    "# context_prefix = 'ptSpecific'\n",
    "context_prefix = 'pooled'\n",
    "fold_data_path = os.path.expanduser('~/workspace/transformer_data/datamodules/') + context_prefix\n",
    "\n",
    "# dm = SimpleMicroDataModule(data, labels, batch_size=batch_size, folds=n_folds,\n",
    "#                            val_size=val_size, augmentations=augmentations, data_path=os.path.expanduser('~/workspace/transformer_data/pt_specific'))\n",
    "## modification of labels for seq2seq RNN ###\n",
    "# dm = SimpleMicroDataModule(data, align_labels, batch_size=batch_size, folds=n_folds,\n",
    "#                            val_size=val_size, augmentations=augmentations, data_path=fold_data_path)\n",
    "\n",
    "\n",
    "# # dm = AlignedMicroDataModule(data, labels, align_labels, pool_data, AlignCCA,\n",
    "# #                             batch_size=batch_size, folds=n_folds, val_size=val_size,\n",
    "# #                             augmentations=augmentations, data_path=fold_data_path)\n",
    "dm = AlignedMicroDataModule(data, align_labels, align_labels, pool_data, AlignCCA,\n",
    "                            batch_size=batch_size, folds=n_folds, val_size=val_size,\n",
    "                            augmentations=augmentations, data_path=fold_data_path)\n",
    "# dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98fad2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4300, 3])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.train_dataloader().dataset.tensors[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1e18287490630e",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ffdeb3bdad199307",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:37:23.785482Z",
     "start_time": "2024-07-10T12:37:23.778265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  | Name          | Type             | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | criterion     | CrossEntropyLoss | 0      | train\n",
      "1 | temporal_conv | TemporalConv     | 111 K  | train\n",
      "2 | encoder       | EncoderRNN       | 6.3 M  | train\n",
      "3 | decoder       | DecoderRNN       | 1.5 M  | train\n",
      "-----------------------------------------------------------\n",
      "7.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.9 M     Total params\n",
      "31.743    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/group/coganlab/zms14/miniconda3/envs/micro_decode/lib/python3.11/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.utilities.model_summary import summarize\n",
    "\n",
    "\n",
    "gclip_val = 0.5\n",
    "\n",
    "##### CNN TRANSFORMER #####\n",
    "\n",
    "# # model parameters\n",
    "# in_channels = data.shape[-1]\n",
    "# num_classes = 9\n",
    "# d_model = 128\n",
    "# # d_model = data.shape[-1]\n",
    "# kernel_time = 50  # ms\n",
    "# kernel_size = int(kernel_time * fs / 1000)  # kernel length in samples\n",
    "# stride_time = 25  # ms\n",
    "# stride = int(stride_time * fs / 1000)  # stride length in samples\n",
    "# padding = 0\n",
    "# n_head = 8\n",
    "# num_layers = 2\n",
    "# dim_fc = 64\n",
    "# # dim_fc = [128, 256, 128, 64]\n",
    "# cnn_dropout = 0.3\n",
    "# tform_dropout = 0.4\n",
    "# learning_rate = 5e-4\n",
    "# l2_reg = 1e-5\n",
    "# gclip_val = 0.5\n",
    "# activ = True\n",
    "\n",
    "# sum_model = CNNTransformer(in_channels, num_classes, d_model, kernel_size, stride, padding,\n",
    "#                            n_head, num_layers, dim_fc, cnn_dropout, tform_dropout, learning_rate)\n",
    "\n",
    "\n",
    "##### Temporal CNN classifier #####\n",
    "\n",
    "# # model parameters\n",
    "# in_channels = data.shape[-1]\n",
    "# num_classes = 9\n",
    "# kernel_time = 50  # ms\n",
    "# kernel_size = int(kernel_time * fs / 1000)  # kernel length in samples\n",
    "# stride_time = 25  # ms\n",
    "# stride = int(stride_time * fs / 1000)  # stride length in samples\n",
    "# padding = 0\n",
    "# dim_fc = [128, 256, 128, 64]\n",
    "# cnn_dropout = 0.3\n",
    "# learning_rate = 5e-4\n",
    "# l2_reg = 1e-5\n",
    "# gclip_val = 0.5\n",
    "# activ = True\n",
    "\n",
    "# sum_model = TCN_classifier(in_channels, num_classes, dim_fc, kernel_size, stride, padding,\n",
    "#                            cnn_dropout, learning_rate, l2_reg)\n",
    "\n",
    "\n",
    "##### Temporal CNN GRU #####\n",
    "\n",
    "# # model parameters\n",
    "# in_channels = data.shape[-1]\n",
    "# num_classes = 9\n",
    "# n_filters = 100\n",
    "# # d_model = data.shape[-1]\n",
    "# kernel_time = 50  # ms\n",
    "# kernel_size = int(kernel_time * fs / 1000)  # kernel length in samples\n",
    "# stride_time = 25  # ms\n",
    "# stride = int(stride_time * fs / 1000)  # stride length in samples\n",
    "# padding = 0\n",
    "# n_layers = 1\n",
    "# hidden_size = 500\n",
    "# dim_fc = [128, 64]\n",
    "# cnn_dropout = 0.3\n",
    "# rnn_dropout = 0.4\n",
    "# learning_rate = 5e-4\n",
    "# l2_reg = 1e-5\n",
    "# activ = True\n",
    "\n",
    "# sum_model = TemporalConvRNN(in_channels, n_filters, num_classes, hidden_size, n_layers,\n",
    "#                             kernel_size, dim_fc, stride, padding, cnn_dropout,\n",
    "#                             rnn_dropout, learning_rate, l2_reg)\n",
    "\n",
    "\n",
    "\n",
    "##### Seq2Seq RNN #####\n",
    "# model parameters\n",
    "in_channels = data.shape[-1]\n",
    "num_classes = 9\n",
    "n_filters = 100\n",
    "# d_model = data.shape[-1]\n",
    "kernel_time = 50  # ms\n",
    "kernel_size = int(kernel_time * fs / 1000)  # kernel length in samples\n",
    "stride_time = 50  # ms\n",
    "stride = int(stride_time * fs / 1000)  # stride length in samples\n",
    "padding = 0\n",
    "n_enc_layers = 2\n",
    "n_dec_layers = 1\n",
    "hidden_size = 500\n",
    "cnn_dropout = 0.3\n",
    "rnn_dropout = 0.3\n",
    "learning_rate = 1e-4\n",
    "l2_reg = 1e-5\n",
    "activ = False\n",
    "model_type = 'gru'\n",
    "\n",
    "sum_model = Seq2SeqRNN(in_channels, n_filters, hidden_size, num_classes, n_enc_layers,\n",
    "                       n_dec_layers, kernel_size, stride, padding, cnn_dropout,\n",
    "                       rnn_dropout, model_type, learning_rate, l2_reg)\n",
    "\n",
    "print(summarize(sum_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad31833df23d804b",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b5454c4b162770f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:37:24.423208Z",
     "start_time": "2024-07-10T12:37:24.417362Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")\n",
    "warnings.filterwarnings(\"ignore\", \"The number of training batches.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b1f762b11299743",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:37:24.431450Z",
     "start_time": "2024-07-10T12:37:24.423208Z"
    }
   },
   "outputs": [],
   "source": [
    "# instantiate the trainer\n",
    "max_epochs = 500\n",
    "# es_pat = max_steps // 20\n",
    "# max_steps = 500\n",
    "es_pat = 50\n",
    "warmup = 100\n",
    "# callbacks = [EarlyStopping(monitor='val_loss', patience=10)]\n",
    "log_dir = os.path.expanduser('~/workspace/transformer_data/transformer_logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddb5ecc37742fee3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:37:24.439028Z",
     "start_time": "2024-07-10T12:37:24.431450Z"
    }
   },
   "outputs": [],
   "source": [
    "# class MetricCollector(L.Callback):\n",
    "#     def __init__(self):\n",
    "#         self.metrics = {}\n",
    "#     \n",
    "#     def on_validation_epoch_end(self, trainer, pl_module):\n",
    "#         self.metrics['val_loss'] = trainer.logger.metrics['val_loss']\n",
    "#         self.metrics['val_acc'] = trainer.logger.metrics['val_acc']\n",
    "#     \n",
    "#     def on_test_epoch_end(self, trainer, pl_module):\n",
    "#         self.metrics['test_loss'] = trainer.logger.metrics['test_loss']\n",
    "#         self.metrics['test_acc'] = trainer.logger.metrics['test_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d553c30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional.classification import multiclass_confusion_matrix\n",
    "\n",
    "def cmat_acc(y_hat, y, num_classes):\n",
    "    y_pred = torch.argmax(y_hat, dim=1)\n",
    "    cmat = multiclass_confusion_matrix(y_pred, y, num_classes)\n",
    "    acc_cmat = cmat.diag().sum() / cmat.sum()\n",
    "    return acc_cmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30910d8dbfaa0aa8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-07-10T12:37:24.440539Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Setting up data module for iteration 1 #####\n"
     ]
    }
   ],
   "source": [
    "acc_dir = os.path.expanduser('~/workspace/transformer_data/accs/')\n",
    "\n",
    "# train the model\n",
    "n_iters = 20\n",
    "iter_accs = []\n",
    "for i in range(n_iters):\n",
    "    print(f'##### Setting up data module for iteration {i+1} #####')\n",
    "    dm.setup()\n",
    "    \n",
    "    fold_accs = []\n",
    "    # y_pred_all = []\n",
    "    # y_test_all = []\n",
    "    for fold in range(n_folds):\n",
    "        # if fold > 1:\n",
    "        #     break\n",
    "        dm.set_fold(fold)\n",
    "        # print(dm.current_fold)\n",
    "        \n",
    "        # instantiate the model\n",
    "        in_channels = dm.get_data_shape()[-1]\n",
    "        # print(in_channels)\n",
    "        # model = CNNTransformer(in_channels, num_classes, d_model, kernel_size, stride, padding,\n",
    "        #                        n_head, num_layers, dim_fc, cnn_dropout, tform_dropout, learning_rate,\n",
    "        #                        warmup, max_steps, l2_reg, activation=activ)\n",
    "        # model = TCN_classifier(in_channels, num_classes, dim_fc, kernel_size, stride, padding,\n",
    "        #                            cnn_dropout, learning_rate, l2_reg, activation=activ)\n",
    "        # model = TemporalConvRNN(in_channels, n_filters, num_classes, hidden_size, n_layers,\n",
    "                                # kernel_size, dim_fc, stride, padding, cnn_dropout,\n",
    "                                # rnn_dropout, learning_rate, l2_reg, activation=activ,\n",
    "                                # decay_iters=max_epochs)\n",
    "        model = Seq2SeqRNN(in_channels, n_filters, hidden_size, num_classes, n_enc_layers,\n",
    "                           n_dec_layers, kernel_size, stride, padding, cnn_dropout, rnn_dropout, model_type,\n",
    "                           learning_rate, l2_reg, activation=activ, decay_iters=max_epochs)\n",
    "        \n",
    "        # model.current_fold = fold\n",
    "        callbacks = [\n",
    "            # ModelCheckpoint(monitor='val_loss', mode='min'),\n",
    "            ModelCheckpoint(monitor='val_acc', mode='max'),\n",
    "            # EarlyStopping(monitor='val_loss', patience=es_pat),\n",
    "            LearningRateMonitor(logging_interval='epoch'),\n",
    "            ]\n",
    "        trainer = L.Trainer(default_root_dir=log_dir,\n",
    "                            max_epochs=max_epochs,\n",
    "                            # max_steps=max_steps,\n",
    "                            gradient_clip_val=gclip_val,\n",
    "                            accelerator='auto',\n",
    "                            callbacks=callbacks,\n",
    "                            logger=True,\n",
    "                            enable_model_summary=False,\n",
    "                            enable_progress_bar=False,\n",
    "                           )\n",
    "        # # trainer.fit(model, dm)\n",
    "        trainer.fit(model=model, train_dataloaders=dm.train_dataloader(), val_dataloaders=dm.val_dataloader())\n",
    "        print(trainer.logged_metrics)\n",
    "        # print(trainer.callback_metrics)\n",
    "        # print the training metrics from the best model checkpoint\n",
    "        # print(f'Fold {fold} best model metrics:')\n",
    "        # print(trainer.checkpoint_callback.best_model_score)\n",
    "\n",
    "\n",
    "        # trainer.test(model, dm)\n",
    "        # model = CNNTransformer.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
    "        trainer.test(model=model, dataloaders=dm.test_dataloader(), ckpt_path='best')\n",
    "        # trainer.test(dataloaders=dm.test_dataloader(), ckpt_path='best')\n",
    "\n",
    "        # test_pred = model(dm.test_dataloader().dataset.tensors[0])\n",
    "        # test_pred = trainer.predict(model, dm.test_dataloader(), ckpt_path='best)[0]\n",
    "        # test_pred = torch.argmax(test_pred, dim=1)\n",
    "        # print(test_pred)\n",
    "        # y_pred_all.extend(test_pred)\n",
    "        # y_test_all.extend(dm.test_dataloader().dataset.tensors[1])\n",
    "        \n",
    "        fold_accs.append(trainer.logged_metrics['test_acc'])\n",
    "    \n",
    "        # save loss information\n",
    "        # loss_dict = trainer.logger.metrics\n",
    "        # loss_dict['fold'] = fold\n",
    "        # loss_dict['model'] = model\n",
    "    # acc = cmat_acc(torch.stack(y_pred_all), torch.stack(y_test_all), num_classes)\n",
    "    # print(acc)\n",
    "    # iter_accs.append(acc)\n",
    "    # print(f'Averaged accuracy: {sum(fold_accs) / len(fold_accs)}')\n",
    "    iter_accs.append(fold_accs)\n",
    "    with open(os.path.join(acc_dir, f'{context_prefix}/{pt}_{context_prefix}_seq2seq_rnn_accs_iter{i+1}.csv'), 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(iter_accs)\n",
    "    print(np.mean(fold_accs))\n",
    "# print(sum(iter_accs) / len(iter_accs), iter_accs)\n",
    "print(iter_accs)\n",
    "with open(os.path.join(acc_dir, f'{context_prefix}/{pt}_{context_prefix}_seq2seq_rnn_accs.csv'), 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(iter_accs)\n",
    "np.save(os.path.join(acc_dir, f'{context_prefix}/{pt}_{context_prefix}_seq2seq_rnn_accs.npy'), np.array(iter_accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93686a0",
   "metadata": {},
   "source": [
    "# View results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f2348ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = 'S14'\n",
    "acc_dir = os.path.expanduser('~/workspace/transformer_data/accs/')\n",
    "context_prefix = 'pooled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e334142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 20)\n",
      "[0.41369048 0.43660712 0.43392858 0.40773812 0.3997024  0.38779765\n",
      " 0.44940478 0.38273808 0.42827377 0.4342262  0.43422619 0.3952381\n",
      " 0.40833336 0.4166667  0.42767859 0.439881   0.4482143  0.42380953\n",
      " 0.43630952 0.42648807]\n",
      "0.42154762\n"
     ]
    }
   ],
   "source": [
    "iter_accs = np.load(os.path.join(acc_dir, f'{context_prefix}/{pt}_{context_prefix}_seq2seq_rnn_accs.npy'))\n",
    "print(iter_accs.shape)\n",
    "print(iter_accs.mean(axis=1))\n",
    "print(iter_accs.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a9b87d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# from torch import tensor\n",
    "# test = [[tensor(0.5000), tensor(0.3636), tensor(0.2727), tensor(0.4545), tensor(0.3182), tensor(0.4545), tensor(0.4091), tensor(0.2273), tensor(0.2727), tensor(0.4091), tensor(0.2727), tensor(0.3182), tensor(0.3333), tensor(0.3333), tensor(0.4762), tensor(0.3333), tensor(0.2857), tensor(0.3810), tensor(0.3810), tensor(0.3810)]]\n",
    "# plt.boxplot(iter_accs.mean(axis=1))\n",
    "sns.boxplot(data=iter_accs.mean(axis=1))\n",
    "sns.swarmplot(data=iter_accs.mean(axis=1), color='black')\n",
    "# sns.boxplot(data=iter_accs.T)\n",
    "# sns.swarmplot(data=iter_accs.T, color='black')\n",
    "plt.axhline(y=1/9, color='gray', linestyle='--')\n",
    "plt.ylim(0, None)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micro_decode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
