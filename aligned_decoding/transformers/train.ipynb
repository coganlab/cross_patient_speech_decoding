{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "629c8e9894f680c6",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9de9524454a74a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T19:00:59.903247Z",
     "start_time": "2024-07-08T19:00:49.644998Z"
    }
   },
   "outputs": [],
   "source": [
    "# %% Imports\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks.model_checkpoint import ModelCheckpoint\n",
    "from pytorch_lightning.utilities.model_summary import summarize\n",
    "import torch\n",
    "from datamodules import SimpleMicroDataModule, CCAMicroDataModule\n",
    "from models import CNNTransformer, Transformer\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from alignment import alignment_utils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae402b0e2a9fc07",
   "metadata": {},
   "source": [
    "# Define data module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a46a71918adb132d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T19:01:05.115184Z",
     "start_time": "2024-07-08T19:00:59.903247Z"
    }
   },
   "outputs": [],
   "source": [
    "# data_filename = '../data/pt_decoding_data_S62.pkl'\n",
    "data_path = os.path.expanduser('~') + '/data/'\n",
    "# data_path = '../data/'\n",
    "data_filename = 'pt_decoding_data_S62.pkl'\n",
    "pt_data = utils.load_pkl(data_path + data_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ced55da2478416b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T19:01:05.125989Z",
     "start_time": "2024-07-08T19:01:05.117607Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(432, 200, 111), (432,), (432, 3)]\n",
      "[[(444, 200, 111), (444,), (444, 3)], [(453, 200, 63), (453,), (453, 3)], [(138, 200, 149), (138,), (138, 3)], [(453, 200, 74), (453,), (453, 3)], [(411, 200, 144), (411,), (411, 3)], [(423, 200, 171), (423,), (423, 3)], [(534, 200, 201), (534,), (534, 3)]]\n"
     ]
    }
   ],
   "source": [
    "pt = 'S14'\n",
    "p_ind = -1\n",
    "lab_type = 'phon'\n",
    "algn_type = 'phon_seq'\n",
    "tar_data, pre_data = utils.decoding_data_from_dict(pt_data, pt, p_ind,\n",
    "                                                   lab_type=lab_type,\n",
    "                                                   algn_type=algn_type)\n",
    "print([d.shape for d in tar_data])\n",
    "print([[d.shape for d in p] for p in pre_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b30a66092a23064f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T19:01:05.257783Z",
     "start_time": "2024-07-08T19:01:05.128999Z"
    }
   },
   "outputs": [],
   "source": [
    "# dummy data\n",
    "# n_samples = 144\n",
    "# n_timepoints = 200\n",
    "# n_features = 111\n",
    "fs = 200 # Hz\n",
    "# data = torch.rand(n_samples, n_timepoints, n_features)\n",
    "# labels = torch.randint(0, 9, (n_samples,))\n",
    "# data = torch.Tensor(all_pt_dict['S14']['X1'])\n",
    "# labels = torch.Tensor(all_pt_dict['S14']['y1']).long() - 1\n",
    "data = torch.Tensor(tar_data[0])\n",
    "labels = torch.Tensor(tar_data[1]).long() - 1\n",
    "align_labels = torch.Tensor(tar_data[2]).long() - 1\n",
    "pool_data = [(torch.Tensor(p[0]), torch.Tensor(p[1]).long() - 1, torch.Tensor(p[2]).long() - 1) for p in pre_data]\n",
    "# data = torch.Tensor(all_pt_dict['S14']['X_collapsed'])\n",
    "# labels = torch.Tensor(all_pt_dict['S14']['y_phon_collapsed']).long() - 1\n",
    "\n",
    "# create the data module\n",
    "batch_size = -1\n",
    "n_folds = 20\n",
    "val_size = 0.1\n",
    "# dm = SimpleMicroDataModule(data, labels, batch_size=batch_size, folds=n_folds,\n",
    "#                            val_size=val_size)\n",
    "dm = CCAMicroDataModule(data, labels, align_labels, pool_data, batch_size=batch_size, folds=n_folds, val_size=val_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1e18287490630e",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffdeb3bdad199307",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T18:44:53.325246Z",
     "start_time": "2024-07-08T18:44:53.311852Z"
    }
   },
   "outputs": [],
   "source": [
    "# model parameters\n",
    "in_channels = data.shape[-1]\n",
    "num_classes = 9\n",
    "d_model = 64\n",
    "# d_model = data.shape[-1]\n",
    "kernel_time = 50  # ms\n",
    "kernel_size = int(kernel_time * fs / 1000)  # kernel length in samples\n",
    "stride_time = 50  # ms\n",
    "stride = int(stride_time * fs / 1000)  # stride length in samples\n",
    "padding = 0\n",
    "n_head = 2\n",
    "num_layers = 2\n",
    "dim_fc = 128\n",
    "dropout = 0.4\n",
    "learning_rate = 5e-4\n",
    "l2_reg = 1e-5\n",
    "gclip_val = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8ee2f751323d2b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T18:44:55.766937Z",
     "start_time": "2024-07-08T18:44:55.747194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  | Name                | Type               | Params | Mode \n",
      "-------------------------------------------------------------------\n",
      "0 | temporal_conv       | TemporalConv       | 71.2 K | train\n",
      "1 | positional_encoding | PositionalEncoding | 0      | train\n",
      "2 | transformer_encoder | TransformerEncoder | 66.9 K | train\n",
      "3 | fc                  | Linear             | 585    | train\n",
      "4 | criterion           | CrossEntropyLoss   | 0      | train\n",
      "-------------------------------------------------------------------\n",
      "138 K     Trainable params\n",
      "0         Non-trainable params\n",
      "138 K     Total params\n",
      "0.555     Total estimated model params size (MB)\n"
     ]
    }
   ],
   "source": [
    "sum_model = CNNTransformer(in_channels, num_classes, d_model, kernel_size, stride, padding,\n",
    "                           n_head, num_layers, dim_fc, dropout, learning_rate)\n",
    "print(summarize(sum_model))\n",
    "# sum_model = Transformer(in_channels, num_classes, d_model, kernel_size, stride, padding,\n",
    "#                            n_head, num_layers, dim_fc, dropout, learning_rate)\n",
    "# print(summarize(sum_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad31833df23d804b",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b5454c4b162770f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T18:44:58.975581Z",
     "start_time": "2024-07-08T18:44:58.961945Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")\n",
    "warnings.filterwarnings(\"ignore\", \"The number of training batches.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b1f762b11299743",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T18:44:59.377982Z",
     "start_time": "2024-07-08T18:44:59.364625Z"
    }
   },
   "outputs": [],
   "source": [
    "# instantiate the trainer\n",
    "max_epochs = 500\n",
    "es_pat = max_epochs // 20\n",
    "# callbacks = [EarlyStopping(monitor='val_loss', patience=10)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ddb5ecc37742fee3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T18:45:00.109686Z",
     "start_time": "2024-07-08T18:45:00.094606Z"
    }
   },
   "outputs": [],
   "source": [
    "# class MetricCollector(L.Callback):\n",
    "#     def __init__(self):\n",
    "#         self.metrics = {}\n",
    "#     \n",
    "#     def on_validation_epoch_end(self, trainer, pl_module):\n",
    "#         self.metrics['val_loss'] = trainer.logger.metrics['val_loss']\n",
    "#         self.metrics['val_acc'] = trainer.logger.metrics['val_acc']\n",
    "#     \n",
    "#     def on_test_epoch_end(self, trainer, pl_module):\n",
    "#         self.metrics['test_loss'] = trainer.logger.metrics['test_loss']\n",
    "#         self.metrics['test_acc'] = trainer.logger.metrics['test_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30910d8dbfaa0aa8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T18:54:44.552276Z",
     "start_time": "2024-07-08T18:45:08.115650Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to restart the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'micro_decode (Python 3.11.9)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "dm.setup()\n",
    "\n",
    "fold_accs = []\n",
    "# for fold in range(n_folds):\n",
    "for fold in range(1):\n",
    "    dm.set_fold(fold)\n",
    "    # print(dm.current_fold)\n",
    "    \n",
    "    # instantiate the model\n",
    "    in_channels = dm.get_data_shape()[-1]\n",
    "    model = CNNTransformer(in_channels, num_classes, d_model, kernel_size, stride, padding,\n",
    "                           n_head, num_layers, dim_fc, dropout, learning_rate)\n",
    "    \n",
    "    # model.current_fold = fold\n",
    "    callbacks = [ModelCheckpoint(monitor='val_loss'), EarlyStopping(monitor='val_loss', patience=es_pat)]\n",
    "    trainer = L.Trainer(max_epochs=max_epochs,\n",
    "                        gradient_clip_val=gclip_val,\n",
    "                        accelerator='auto',\n",
    "                        callbacks=callbacks,\n",
    "                        logger=True,\n",
    "                        enable_model_summary=False,\n",
    "                        # enable_progress_bar=False,\n",
    "                       )\n",
    "    trainer.fit(model, dm)\n",
    "    print(trainer.logged_metrics)\n",
    "    trainer.test(model, dm)\n",
    "    fold_accs.append(trainer.logged_metrics['test_acc'])\n",
    "\n",
    "    # save loss information\n",
    "    # loss_dict = trainer.logger.metrics\n",
    "    # loss_dict['fold'] = fold\n",
    "    # loss_dict['model'] = model\n",
    "print(f'Averaged accuracy: {sum(fold_accs) / len(fold_accs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfc21c01630ca5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T18:14:07.348407Z",
     "start_time": "2024-07-08T18:14:07.348407Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
