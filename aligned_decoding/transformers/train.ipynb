{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "629c8e9894f680c6",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9de9524454a74a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:36:37.423150Z",
     "start_time": "2024-07-10T12:36:26.252451Z"
    }
   },
   "outputs": [],
   "source": [
    "# %% Imports\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint, LearningRateMonitor\n",
    "from pytorch_lightning.utilities.model_summary import summarize\n",
    "import torch\n",
    "import numpy as np\n",
    "from datamodules import SimpleMicroDataModule, AlignedMicroDataModule\n",
    "from models import CNNTransformer, Transformer, TCN_classifier\n",
    "import augmentations as augs\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from alignment import alignment_utils as utils\n",
    "from alignment.AlignCCA import AlignCCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae402b0e2a9fc07",
   "metadata": {},
   "source": [
    "# Define data module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a46a71918adb132d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:36:42.704611Z",
     "start_time": "2024-07-10T12:36:37.423150Z"
    }
   },
   "outputs": [],
   "source": [
    "data_filename = os.path.expanduser('~/data/pt_decoding_data_S62.pkl')\n",
    "pt_data = utils.load_pkl(data_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ced55da2478416b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:36:42.715275Z",
     "start_time": "2024-07-10T12:36:42.704611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(432, 200, 111), (432,), (432, 3)]\n",
      "[[(444, 200, 111), (444,), (444, 3)], [(453, 200, 63), (453,), (453, 3)], [(138, 200, 149), (138,), (138, 3)], [(453, 200, 74), (453,), (453, 3)], [(411, 200, 144), (411,), (411, 3)], [(423, 200, 171), (423,), (423, 3)], [(534, 200, 201), (534,), (534, 3)]]\n"
     ]
    }
   ],
   "source": [
    "pt = 'S14'\n",
    "p_ind = -1\n",
    "lab_type = 'phon'\n",
    "algn_type = 'phon_seq'\n",
    "tar_data, pre_data = utils.decoding_data_from_dict(pt_data, pt, p_ind,\n",
    "                                                   lab_type=lab_type,\n",
    "                                                   algn_type=algn_type)\n",
    "print([d.shape for d in tar_data])\n",
    "print([[d.shape for d in p] for p in pre_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b30a66092a23064f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:37:23.778265Z",
     "start_time": "2024-07-10T12:36:42.715275Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 28\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# dm = SimpleMicroDataModule(data, labels, batch_size=batch_size, folds=n_folds,\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#                            val_size=val_size, augmentations=augmentations, data_path=os.path.expanduser('~/workspace/transformer_data/pt_specific'))\u001b[39;00m\n\u001b[1;32m     25\u001b[0m dm \u001b[38;5;241m=\u001b[39m AlignedMicroDataModule(data, labels, align_labels, pool_data, AlignCCA,\n\u001b[1;32m     26\u001b[0m                             batch_size\u001b[38;5;241m=\u001b[39mbatch_size, folds\u001b[38;5;241m=\u001b[39mn_folds, val_size\u001b[38;5;241m=\u001b[39mval_size,\n\u001b[1;32m     27\u001b[0m                             augmentations\u001b[38;5;241m=\u001b[39maugmentations, data_path\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m~/workspace/transformer_data\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m---> 28\u001b[0m dm\u001b[38;5;241m.\u001b[39msetup()\n",
      "File \u001b[0;32m~/repos/cross_patient_speech_decoding/aligned_decoding/transformers/datamodules.py:215\u001b[0m, in \u001b[0;36mAlignedMicroDataModule.setup\u001b[0;34m(self, stage)\u001b[0m\n\u001b[1;32m    207\u001b[0m         aug_pool_data[i][\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((aug_pool_data[i][\u001b[38;5;241m2\u001b[39m], y_a))\n\u001b[1;32m    210\u001b[0m \u001b[38;5;66;03m# align pooled data to current data\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;66;03m# train_data, train_labels, dim_red = (\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m#     process_aligner(train_data, train_labels, align_labels,\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;66;03m#                     self.pool_data, self.algner))\u001b[39;00m\n\u001b[1;32m    214\u001b[0m aug_data, aug_labels, dim_red \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 215\u001b[0m     process_aligner(aug_data, aug_labels, aug_align_labels,\n\u001b[1;32m    216\u001b[0m                     aug_pool_data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malgner))\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# aug_data = torch.Tensor([])\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# aug_labels = torch.Tensor([]).long()\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;66;03m# for aug in self.augmentations:\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;66;03m#     aug_data = torch.cat((aug_data, aug(train_data)))\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;66;03m#     aug_labels = torch.cat((aug_labels, train_labels))\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/repos/cross_patient_speech_decoding/aligned_decoding/transformers/datamodules.py:334\u001b[0m, in \u001b[0;36mprocess_aligner\u001b[0;34m(X, y, y_align, pool_data, algner, n_components)\u001b[0m\n\u001b[1;32m    331\u001b[0m X_tar_r \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    333\u001b[0m \u001b[38;5;66;03m# reduce dimensionality of cross-patient data\u001b[39;00m\n\u001b[0;32m--> 334\u001b[0m X_cross_dr \u001b[38;5;241m=\u001b[39m [PCA(n_components\u001b[38;5;241m=\u001b[39mn_components)\u001b[38;5;241m.\u001b[39mfit_transform(x)\n\u001b[1;32m    335\u001b[0m               \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X_cross_r]\n\u001b[1;32m    337\u001b[0m \u001b[38;5;66;03m# reduce dimensionality of target data, saving dim. red. object for\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;66;03m# test set\u001b[39;00m\n\u001b[1;32m    339\u001b[0m tar_dr \u001b[38;5;241m=\u001b[39m PCA(n_components\u001b[38;5;241m=\u001b[39mn_components)\n",
      "File \u001b[0;32m~/repos/cross_patient_speech_decoding/aligned_decoding/transformers/datamodules.py:334\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    331\u001b[0m X_tar_r \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    333\u001b[0m \u001b[38;5;66;03m# reduce dimensionality of cross-patient data\u001b[39;00m\n\u001b[0;32m--> 334\u001b[0m X_cross_dr \u001b[38;5;241m=\u001b[39m [PCA(n_components\u001b[38;5;241m=\u001b[39mn_components)\u001b[38;5;241m.\u001b[39mfit_transform(x)\n\u001b[1;32m    335\u001b[0m               \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X_cross_r]\n\u001b[1;32m    337\u001b[0m \u001b[38;5;66;03m# reduce dimensionality of target data, saving dim. red. object for\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;66;03m# test set\u001b[39;00m\n\u001b[1;32m    339\u001b[0m tar_dr \u001b[38;5;241m=\u001b[39m PCA(n_components\u001b[38;5;241m=\u001b[39mn_components)\n",
      "File \u001b[0;32m/hpc/group/coganlab/zms14/miniconda3/envs/micro_decode/lib/python3.11/site-packages/sklearn/utils/_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    301\u001b[0m         )\n",
      "File \u001b[0;32m/hpc/group/coganlab/zms14/miniconda3/envs/micro_decode/lib/python3.11/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/hpc/group/coganlab/zms14/miniconda3/envs/micro_decode/lib/python3.11/site-packages/sklearn/decomposition/_pca.py:454\u001b[0m, in \u001b[0;36mPCA.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    433\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model with X and apply the dimensionality reduction on X.\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \n\u001b[1;32m    435\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;124;03m    C-ordered array, use 'np.ascontiguousarray'.\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 454\u001b[0m     U, S, Vt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X)\n\u001b[1;32m    455\u001b[0m     U \u001b[38;5;241m=\u001b[39m U[:, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components_]\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwhiten:\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;66;03m# X_new = X * V / S * sqrt(n_samples) = U * sqrt(n_samples)\u001b[39;00m\n",
      "File \u001b[0;32m/hpc/group/coganlab/zms14/miniconda3/envs/micro_decode/lib/python3.11/site-packages/sklearn/decomposition/_pca.py:483\u001b[0m, in \u001b[0;36mPCA._fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msvd_solver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marpack\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_array_api_compliant:\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPCA with svd_solver=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marpack\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not supported for Array API inputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    481\u001b[0m     )\n\u001b[0;32m--> 483\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m    484\u001b[0m     X,\n\u001b[1;32m    485\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m[xp\u001b[38;5;241m.\u001b[39mfloat64, xp\u001b[38;5;241m.\u001b[39mfloat32],\n\u001b[1;32m    486\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    487\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    488\u001b[0m     copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy,\n\u001b[1;32m    489\u001b[0m )\n\u001b[1;32m    491\u001b[0m \u001b[38;5;66;03m# Handle n_components==None\u001b[39;00m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/hpc/group/coganlab/zms14/miniconda3/envs/micro_decode/lib/python3.11/site-packages/sklearn/base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m/hpc/group/coganlab/zms14/miniconda3/envs/micro_decode/lib/python3.11/site-packages/sklearn/utils/validation.py:997\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    995\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    996\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 997\u001b[0m         array \u001b[38;5;241m=\u001b[39m _asarray_with_order(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[1;32m    998\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m    999\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1000\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m   1001\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m/hpc/group/coganlab/zms14/miniconda3/envs/micro_decode/lib/python3.11/site-packages/sklearn/utils/_array_api.py:521\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    519\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 521\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    523\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[0;32m/hpc/group/coganlab/zms14/miniconda3/envs/micro_decode/lib/python3.11/site-packages/torch/_tensor.py:1089\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1087\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# dummy data\n",
    "# n_samples = 144\n",
    "# n_timepoints = 200\n",
    "# n_features = 111\n",
    "fs = 200 # Hz\n",
    "augmentations = [augs.time_warping, augs.time_masking, augs.time_shifting, augs.noise_jitter, augs.scaling]\n",
    "# augmentations = None\n",
    "# data = torch.rand(n_samples, n_timepoints, n_features)\n",
    "# labels = torch.randint(0, 9, (n_samples,))\n",
    "# data = torch.Tensor(all_pt_dict['S14']['X1'])\n",
    "# labels = torch.Tensor(all_pt_dict['S14']['y1']).long() - 1\n",
    "data = torch.Tensor(tar_data[0])\n",
    "labels = torch.Tensor(tar_data[1]).long() - 1\n",
    "align_labels = torch.Tensor(tar_data[2]).long() - 1\n",
    "pool_data = [(torch.Tensor(p[0]), torch.Tensor(p[1]).long() - 1, torch.Tensor(p[2]).long() - 1) for p in pre_data]\n",
    "# data = torch.Tensor(all_pt_dict['S14']['X_collapsed'])\n",
    "# labels = torch.Tensor(all_pt_dict['S14']['y_phon_collapsed']).long() - 1\n",
    "\n",
    "# create the data module\n",
    "batch_size = -1\n",
    "n_folds = 20\n",
    "val_size = 0.1\n",
    "# dm = SimpleMicroDataModule(data, labels, batch_size=batch_size, folds=n_folds,\n",
    "#                            val_size=val_size, augmentations=augmentations, data_path=os.path.expanduser('~/workspace/transformer_data/pt_specific'))\n",
    "dm = AlignedMicroDataModule(data, labels, align_labels, pool_data, AlignCCA,\n",
    "                            batch_size=batch_size, folds=n_folds, val_size=val_size,\n",
    "                            augmentations=augmentations, data_path=os.path.expanduser('~/workspace/transformer_data'))\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1e18287490630e",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffdeb3bdad199307",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:37:23.785482Z",
     "start_time": "2024-07-10T12:37:23.778265Z"
    }
   },
   "outputs": [],
   "source": [
    "# model parameters\n",
    "in_channels = data.shape[-1]\n",
    "num_classes = 9\n",
    "d_model = 128\n",
    "# d_model = data.shape[-1]\n",
    "kernel_time = 50  # ms\n",
    "kernel_size = int(kernel_time * fs / 1000)  # kernel length in samples\n",
    "stride_time = 25  # ms\n",
    "stride = int(stride_time * fs / 1000)  # stride length in samples\n",
    "padding = 0\n",
    "n_head = 8\n",
    "num_layers = 2\n",
    "# dim_fc = 64\n",
    "dim_fc = [128, 64, 32]\n",
    "cnn_dropout = 0.2\n",
    "tform_dropout = 0.4\n",
    "learning_rate = 1e-3\n",
    "l2_reg = 1e-5\n",
    "gclip_val = 0.5\n",
    "activ = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc6e3e0a4501e5a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:37:24.327137Z",
     "start_time": "2024-07-10T12:37:23.785482Z"
    }
   },
   "outputs": [],
   "source": [
    "from pytorch_lightning.utilities.model_summary import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8ee2f751323d2b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:37:24.417362Z",
     "start_time": "2024-07-10T12:37:24.328723Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  | Name          | Type             | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | temporal_conv | TemporalConv     | 142 K  | train\n",
      "1 | fc            | Sequential       | 10.6 K | train\n",
      "2 | criterion     | CrossEntropyLoss | 0      | train\n",
      "-----------------------------------------------------------\n",
      "153 K     Trainable params\n",
      "0         Non-trainable params\n",
      "153 K     Total params\n",
      "0.612     Total estimated model params size (MB)\n"
     ]
    }
   ],
   "source": [
    "# sum_model = CNNTransformer(in_channels, num_classes, d_model, kernel_size, stride, padding,\n",
    "#                            n_head, num_layers, dim_fc, cnn_dropout, tform_dropout, learning_rate)\n",
    "sum_model = TCN_classifier(in_channels, num_classes, dim_fc, kernel_size, stride, padding,\n",
    "                           cnn_dropout, learning_rate, l2_reg)\n",
    "print(summarize(sum_model))\n",
    "# sum_model = Transformer(in_channels, num_classes, d_model, kernel_size, stride, padding,\n",
    "#                            n_head, num_layers, dim_fc, dropout, learning_rate)\n",
    "# print(summarize(sum_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad31833df23d804b",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b5454c4b162770f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:37:24.423208Z",
     "start_time": "2024-07-10T12:37:24.417362Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")\n",
    "warnings.filterwarnings(\"ignore\", \"The number of training batches.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b1f762b11299743",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:37:24.431450Z",
     "start_time": "2024-07-10T12:37:24.423208Z"
    }
   },
   "outputs": [],
   "source": [
    "# instantiate the trainer\n",
    "# max_epochs = 500\n",
    "# es_pat = max_steps // 20\n",
    "max_steps = 500\n",
    "es_pat = 25\n",
    "warmup = 50\n",
    "# callbacks = [EarlyStopping(monitor='val_loss', patience=10)]\n",
    "log_dir = os.path.expanduser('~/workspace/transformer_data/transformer_logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ddb5ecc37742fee3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:37:24.439028Z",
     "start_time": "2024-07-10T12:37:24.431450Z"
    }
   },
   "outputs": [],
   "source": [
    "# class MetricCollector(L.Callback):\n",
    "#     def __init__(self):\n",
    "#         self.metrics = {}\n",
    "#     \n",
    "#     def on_validation_epoch_end(self, trainer, pl_module):\n",
    "#         self.metrics['val_loss'] = trainer.logger.metrics['val_loss']\n",
    "#         self.metrics['val_acc'] = trainer.logger.metrics['val_acc']\n",
    "#     \n",
    "#     def on_test_epoch_end(self, trainer, pl_module):\n",
    "#         self.metrics['test_loss'] = trainer.logger.metrics['test_loss']\n",
    "#         self.metrics['test_acc'] = trainer.logger.metrics['test_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d553c30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional.classification import multiclass_confusion_matrix\n",
    "\n",
    "def cmat_acc(y_hat, y, num_classes):\n",
    "    y_pred = torch.argmax(y_hat, dim=1)\n",
    "    cmat = multiclass_confusion_matrix(y_pred, y, num_classes)\n",
    "    acc_cmat = cmat.diag().sum() / cmat.sum()\n",
    "    return acc_cmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30910d8dbfaa0aa8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-07-10T12:37:24.440539Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/group/coganlab/zms14/miniconda3/envs/micro_decode/lib/python3.11/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /hpc/group/coganlab/zms14/miniconda3/envs/micro_deco ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/hpc/group/coganlab/zms14/miniconda3/envs/micro_decode/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Restoring states from the checkpoint path at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_847/checkpoints/epoch=111-step=224.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_847/checkpoints/epoch=111-step=224.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': tensor(0.1739), 'train_acc': tensor(0.9904), 'val_loss': tensor(1.7967), 'val_acc': tensor(0.2857)}\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc                   0.375\n",
      "        test_loss           1.7319660186767578\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Restoring states from the checkpoint path at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_848/checkpoints/epoch=66-step=134.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_848/checkpoints/epoch=66-step=134.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': tensor(0.5582), 'train_acc': tensor(0.9135), 'val_loss': tensor(2.0847), 'val_acc': tensor(0.2143)}\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc                   0.375\n",
      "        test_loss           1.6023768186569214\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Restoring states from the checkpoint path at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_849/checkpoints/epoch=163-step=328.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /hpc/home/zms14/workspace/transformer_data/transformer_logs/lightning_logs/version_849/checkpoints/epoch=163-step=328.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': tensor(0.0823), 'train_acc': tensor(0.9942), 'val_loss': tensor(1.6062), 'val_acc': tensor(0.3571)}\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc                   0.625\n",
      "        test_loss           1.6224404573440552\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "0.45833334\n",
      "[[tensor(0.3750), tensor(0.3750), tensor(0.6250)]]\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "n_iters = 1\n",
    "iter_accs = []\n",
    "for i in range(n_iters):\n",
    "    # dm.setup()\n",
    "    \n",
    "    fold_accs = []\n",
    "    # y_pred_all = []\n",
    "    # y_test_all = []\n",
    "    for fold in range(n_folds):\n",
    "        if fold > 2:\n",
    "            break\n",
    "        dm.set_fold(fold)\n",
    "        # print(dm.current_fold)\n",
    "        \n",
    "        # instantiate the model\n",
    "        in_channels = dm.get_data_shape()[-1]\n",
    "        # print(in_channels)\n",
    "        # model = CNNTransformer(in_channels, num_classes, d_model, kernel_size, stride, padding,\n",
    "        #                        n_head, num_layers, dim_fc, cnn_dropout, tform_dropout, learning_rate,\n",
    "        #                        warmup, max_steps, l2_reg, activation=activ)\n",
    "        model = TCN_classifier(in_channels, num_classes, dim_fc, kernel_size, stride, padding,\n",
    "                                   cnn_dropout, learning_rate, l2_reg, activation=activ)\n",
    "        \n",
    "        # model.current_fold = fold\n",
    "        callbacks = [\n",
    "            ModelCheckpoint(monitor='val_loss'),\n",
    "            EarlyStopping(monitor='val_loss', patience=es_pat),\n",
    "            LearningRateMonitor(logging_interval='epoch'),\n",
    "            ]\n",
    "        trainer = L.Trainer(default_root_dir=log_dir,\n",
    "                            # max_epochs=max_epochs,\n",
    "                            max_steps=max_steps,\n",
    "                            gradient_clip_val=gclip_val,\n",
    "                            accelerator='auto',\n",
    "                            callbacks=callbacks,\n",
    "                            logger=True,\n",
    "                            enable_model_summary=False,\n",
    "                            enable_progress_bar=False,\n",
    "                           )\n",
    "        # # trainer.fit(model, dm)\n",
    "        trainer.fit(model=model, train_dataloaders=dm.train_dataloader(), val_dataloaders=dm.val_dataloader())\n",
    "        print(trainer.logged_metrics)\n",
    "        # print the training metrics from the best model checkpoint\n",
    "        # print(f'Fold {fold} best model metrics:')\n",
    "        # print(trainer.checkpoint_callback.best_model_score)\n",
    "\n",
    "\n",
    "        # trainer.test(model, dm)\n",
    "        # model = CNNTransformer.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
    "        trainer.test(model=model, dataloaders=dm.test_dataloader(), ckpt_path='best')\n",
    "        # trainer.test(dataloaders=dm.test_dataloader(), ckpt_path='best')\n",
    "\n",
    "        # test_pred = model(dm.test_dataloader().dataset.tensors[0])\n",
    "        # test_pred = trainer.predict(model, dm.test_dataloader(), ckpt_path='best)[0]\n",
    "        # test_pred = torch.argmax(test_pred, dim=1)\n",
    "        # print(test_pred)\n",
    "        # y_pred_all.extend(test_pred)\n",
    "        # y_test_all.extend(dm.test_dataloader().dataset.tensors[1])\n",
    "        \n",
    "        fold_accs.append(trainer.logged_metrics['test_acc'])\n",
    "    \n",
    "        # save loss information\n",
    "        # loss_dict = trainer.logger.metrics\n",
    "        # loss_dict['fold'] = fold\n",
    "        # loss_dict['model'] = model\n",
    "    # acc = cmat_acc(torch.stack(y_pred_all), torch.stack(y_test_all), num_classes)\n",
    "    # print(acc)\n",
    "    # iter_accs.append(acc)\n",
    "    # print(f'Averaged accuracy: {sum(fold_accs) / len(fold_accs)}')\n",
    "    iter_accs.append(fold_accs)\n",
    "    print(np.mean(fold_accs))\n",
    "# print(sum(iter_accs) / len(iter_accs), iter_accs)\n",
    "print(iter_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a9b87d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch import tensor\n",
    "# test = [[tensor(0.5000), tensor(0.3636), tensor(0.2727), tensor(0.4545), tensor(0.3182), tensor(0.4545), tensor(0.4091), tensor(0.2273), tensor(0.2727), tensor(0.4091), tensor(0.2727), tensor(0.3182), tensor(0.3333), tensor(0.3333), tensor(0.4762), tensor(0.3333), tensor(0.2857), tensor(0.3810), tensor(0.3810), tensor(0.3810)]]\n",
    "plt.boxplot(fold_accs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc82690e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20790043"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.mean(fold_accs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
