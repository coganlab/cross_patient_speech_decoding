{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "629c8e9894f680c6",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9de9524454a74a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:36:37.423150Z",
     "start_time": "2024-07-10T12:36:26.252451Z"
    }
   },
   "outputs": [],
   "source": [
    "# %% Imports\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint, LearningRateMonitor\n",
    "from pytorch_lightning.utilities.model_summary import summarize\n",
    "import torch\n",
    "import numpy as np\n",
    "from datamodules import SimpleMicroDataModule, AlignedMicroDataModule\n",
    "from models import CNNTransformer, Transformer, TCN_classifier\n",
    "import augmentations as augs\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from alignment import alignment_utils as utils\n",
    "from alignment.AlignCCA import AlignCCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae402b0e2a9fc07",
   "metadata": {},
   "source": [
    "# Define data module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a46a71918adb132d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:36:42.704611Z",
     "start_time": "2024-07-10T12:36:37.423150Z"
    }
   },
   "outputs": [],
   "source": [
    "# data_filename = os.path.expanduser('~/data/pt_decoding_data_S62.pkl')\n",
    "data_filename = ('../data/pt_decoding_data_S62.pkl')\n",
    "pt_data = utils.load_pkl(data_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ced55da2478416b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:36:42.715275Z",
     "start_time": "2024-07-10T12:36:42.704611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(432, 200, 111), (432,), (432, 3)]\n",
      "[[(444, 200, 111), (444,), (444, 3)], [(453, 200, 63), (453,), (453, 3)], [(138, 200, 149), (138,), (138, 3)], [(453, 200, 74), (453,), (453, 3)], [(411, 200, 144), (411,), (411, 3)], [(423, 200, 171), (423,), (423, 3)], [(534, 200, 201), (534,), (534, 3)]]\n"
     ]
    }
   ],
   "source": [
    "pt = 'S14'\n",
    "p_ind = -1\n",
    "lab_type = 'phon'\n",
    "algn_type = 'phon_seq'\n",
    "tar_data, pre_data = utils.decoding_data_from_dict(pt_data, pt, p_ind,\n",
    "                                                   lab_type=lab_type,\n",
    "                                                   algn_type=algn_type)\n",
    "print([d.shape for d in tar_data])\n",
    "print([[d.shape for d in p] for p in pre_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b30a66092a23064f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:37:23.778265Z",
     "start_time": "2024-07-10T12:36:42.715275Z"
    }
   },
   "outputs": [],
   "source": [
    "fold_data_path = os.path.expanduser('~/workspace/transformer_data')\n",
    "fold_data_path = '.'\n",
    "\n",
    "fs = 200 # Hz\n",
    "augmentations = [augs.time_warping, augs.time_masking, augs.time_shifting, augs.noise_jitter, augs.scaling]\n",
    "# augmentations = None\n",
    "# data = torch.rand(n_samples, n_timepoints, n_features)\n",
    "# labels = torch.randint(0, 9, (n_samples,))\n",
    "# data = torch.Tensor(all_pt_dict['S14']['X1'])\n",
    "# labels = torch.Tensor(all_pt_dict['S14']['y1']).long() - 1\n",
    "data = torch.Tensor(tar_data[0])\n",
    "labels = torch.Tensor(tar_data[1]).long() - 1\n",
    "align_labels = torch.Tensor(tar_data[2]).long() - 1\n",
    "pool_data = [(torch.Tensor(p[0]), torch.Tensor(p[1]).long() - 1, torch.Tensor(p[2]).long() - 1) for p in pre_data]\n",
    "# data = torch.Tensor(all_pt_dict['S14']['X_collapsed'])\n",
    "# labels = torch.Tensor(all_pt_dict['S14']['y_phon_collapsed']).long() - 1\n",
    "\n",
    "# create the data module\n",
    "batch_size = -1\n",
    "n_folds = 20\n",
    "val_size = 0.1\n",
    "# dm = SimpleMicroDataModule(data, labels, batch_size=batch_size, folds=n_folds,\n",
    "#                            val_size=val_size, augmentations=augmentations, data_path=os.path.expanduser('~/workspace/transformer_data/pt_specific'))\n",
    "dm = AlignedMicroDataModule(data, labels, align_labels, pool_data, AlignCCA,\n",
    "                            batch_size=batch_size, folds=n_folds, val_size=val_size,\n",
    "                            augmentations=augmentations, data_path=fold_data_path)\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1e18287490630e",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffdeb3bdad199307",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:37:23.785482Z",
     "start_time": "2024-07-10T12:37:23.778265Z"
    }
   },
   "outputs": [],
   "source": [
    "# model parameters\n",
    "in_channels = data.shape[-1]\n",
    "num_classes = 9\n",
    "d_model = 128\n",
    "# d_model = data.shape[-1]\n",
    "kernel_time = 50  # ms\n",
    "kernel_size = int(kernel_time * fs / 1000)  # kernel length in samples\n",
    "stride_time = 50  # ms\n",
    "stride = int(stride_time * fs / 1000)  # stride length in samples\n",
    "padding = 0\n",
    "n_head = 8\n",
    "num_layers = 2\n",
    "# dim_fc = 64\n",
    "dim_fc = [64, 32]\n",
    "cnn_dropout = 0.2\n",
    "tform_dropout = 0.4\n",
    "learning_rate = 5e-4\n",
    "l2_reg = 1e-5\n",
    "gclip_val = 0.5\n",
    "activ = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc6e3e0a4501e5a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:37:24.327137Z",
     "start_time": "2024-07-10T12:37:23.785482Z"
    }
   },
   "outputs": [],
   "source": [
    "from pytorch_lightning.utilities.model_summary import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8ee2f751323d2b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:37:24.417362Z",
     "start_time": "2024-07-10T12:37:24.328723Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  | Name          | Type             | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | temporal_conv | TemporalConv     | 71.2 K | train\n",
      "1 | fc            | Sequential       | 2.4 K  | train\n",
      "2 | criterion     | CrossEntropyLoss | 0      | train\n",
      "-----------------------------------------------------------\n",
      "73.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "73.6 K    Total params\n",
      "0.294     Total estimated model params size (MB)\n"
     ]
    }
   ],
   "source": [
    "# sum_model = CNNTransformer(in_channels, num_classes, d_model, kernel_size, stride, padding,\n",
    "#                            n_head, num_layers, dim_fc, cnn_dropout, tform_dropout, learning_rate)\n",
    "sum_model = TCN_classifier(in_channels, num_classes, dim_fc, kernel_size, stride, padding,\n",
    "                           cnn_dropout, learning_rate, l2_reg)\n",
    "print(summarize(sum_model))\n",
    "# sum_model = Transformer(in_channels, num_classes, d_model, kernel_size, stride, padding,\n",
    "#                            n_head, num_layers, dim_fc, dropout, learning_rate)\n",
    "# print(summarize(sum_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad31833df23d804b",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b5454c4b162770f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:37:24.423208Z",
     "start_time": "2024-07-10T12:37:24.417362Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")\n",
    "warnings.filterwarnings(\"ignore\", \"The number of training batches.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b1f762b11299743",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:37:24.431450Z",
     "start_time": "2024-07-10T12:37:24.423208Z"
    }
   },
   "outputs": [],
   "source": [
    "# instantiate the trainer\n",
    "# max_epochs = 500\n",
    "# es_pat = max_steps // 20\n",
    "max_steps = 500\n",
    "es_pat = 25\n",
    "warmup = 50\n",
    "# callbacks = [EarlyStopping(monitor='val_loss', patience=10)]\n",
    "log_dir = os.path.expanduser('~/workspace/transformer_data/transformer_logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddb5ecc37742fee3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:37:24.439028Z",
     "start_time": "2024-07-10T12:37:24.431450Z"
    }
   },
   "outputs": [],
   "source": [
    "# class MetricCollector(L.Callback):\n",
    "#     def __init__(self):\n",
    "#         self.metrics = {}\n",
    "#     \n",
    "#     def on_validation_epoch_end(self, trainer, pl_module):\n",
    "#         self.metrics['val_loss'] = trainer.logger.metrics['val_loss']\n",
    "#         self.metrics['val_acc'] = trainer.logger.metrics['val_acc']\n",
    "#     \n",
    "#     def on_test_epoch_end(self, trainer, pl_module):\n",
    "#         self.metrics['test_loss'] = trainer.logger.metrics['test_loss']\n",
    "#         self.metrics['test_acc'] = trainer.logger.metrics['test_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d553c30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional.classification import multiclass_confusion_matrix\n",
    "\n",
    "def cmat_acc(y_hat, y, num_classes):\n",
    "    y_pred = torch.argmax(y_hat, dim=1)\n",
    "    cmat = multiclass_confusion_matrix(y_pred, y, num_classes)\n",
    "    acc_cmat = cmat.diag().sum() / cmat.sum()\n",
    "    return acc_cmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30910d8dbfaa0aa8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-07-10T12:37:24.440539Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Restoring states from the checkpoint path at C:\\Users\\zms14\\workspace\\transformer_data\\transformer_logs\\lightning_logs\\version_6\\checkpoints\\epoch=52-step=318.ckpt\n",
      "Loaded model weights from the checkpoint at C:\\Users\\zms14\\workspace\\transformer_data\\transformer_logs\\lightning_logs\\version_6\\checkpoints\\epoch=52-step=318.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': tensor(1.7216), 'train_acc': tensor(0.4055), 'val_loss': tensor(2.0702), 'val_acc': tensor(0.1707)}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.27272728085517883    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    2.0416815280914307     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.27272728085517883   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   2.0416815280914307    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_steps=500` reached.\n",
      "Restoring states from the checkpoint path at C:\\Users\\zms14\\workspace\\transformer_data\\transformer_logs\\lightning_logs\\version_7\\checkpoints\\epoch=78-step=474.ckpt\n",
      "Loaded model weights from the checkpoint at C:\\Users\\zms14\\workspace\\transformer_data\\transformer_logs\\lightning_logs\\version_7\\checkpoints\\epoch=78-step=474.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': tensor(1.7337), 'train_acc': tensor(0.3717), 'val_loss': tensor(2.0652), 'val_acc': tensor(0.2439)}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.13636364042758942    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    2.0136773586273193     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.13636364042758942   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   2.0136773586273193    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_steps=500` reached.\n",
      "Restoring states from the checkpoint path at C:\\Users\\zms14\\workspace\\transformer_data\\transformer_logs\\lightning_logs\\version_8\\checkpoints\\epoch=63-step=384.ckpt\n",
      "Loaded model weights from the checkpoint at C:\\Users\\zms14\\workspace\\transformer_data\\transformer_logs\\lightning_logs\\version_8\\checkpoints\\epoch=63-step=384.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': tensor(1.6880), 'train_acc': tensor(0.4106), 'val_loss': tensor(2.1357), 'val_acc': tensor(0.2195)}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.22727273404598236    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     1.97542142868042      </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.22727273404598236   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    1.97542142868042     \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21212123\n",
      "[[tensor(0.2727), tensor(0.1364), tensor(0.2273)]]\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "n_iters = 1\n",
    "iter_accs = []\n",
    "for i in range(n_iters):\n",
    "    # dm.setup()\n",
    "    \n",
    "    fold_accs = []\n",
    "    # y_pred_all = []\n",
    "    # y_test_all = []\n",
    "    for fold in range(n_folds):\n",
    "        if fold > 2:\n",
    "            break\n",
    "        dm.set_fold(fold)\n",
    "        # print(dm.current_fold)\n",
    "        \n",
    "        # instantiate the model\n",
    "        in_channels = dm.get_data_shape()[-1]\n",
    "        # print(in_channels)\n",
    "        # model = CNNTransformer(in_channels, num_classes, d_model, kernel_size, stride, padding,\n",
    "        #                        n_head, num_layers, dim_fc, cnn_dropout, tform_dropout, learning_rate,\n",
    "        #                        warmup, max_steps, l2_reg, activation=activ)\n",
    "        model = TCN_classifier(in_channels, num_classes, dim_fc, kernel_size, stride, padding,\n",
    "                                   cnn_dropout, learning_rate, l2_reg, activation=activ)\n",
    "        \n",
    "        # model.current_fold = fold\n",
    "        callbacks = [\n",
    "            ModelCheckpoint(monitor='val_loss'),\n",
    "            EarlyStopping(monitor='val_loss', patience=es_pat),\n",
    "            LearningRateMonitor(logging_interval='epoch'),\n",
    "            ]\n",
    "        trainer = L.Trainer(default_root_dir=log_dir,\n",
    "                            # max_epochs=max_epochs,\n",
    "                            max_steps=max_steps,\n",
    "                            gradient_clip_val=gclip_val,\n",
    "                            accelerator='auto',\n",
    "                            callbacks=callbacks,\n",
    "                            logger=True,\n",
    "                            enable_model_summary=False,\n",
    "                            enable_progress_bar=False,\n",
    "                           )\n",
    "        # # trainer.fit(model, dm)\n",
    "        trainer.fit(model=model, train_dataloaders=dm.train_dataloader(), val_dataloaders=dm.val_dataloader())\n",
    "        print(trainer.logged_metrics)\n",
    "        # print the training metrics from the best model checkpoint\n",
    "        # print(f'Fold {fold} best model metrics:')\n",
    "        # print(trainer.checkpoint_callback.best_model_score)\n",
    "\n",
    "\n",
    "        # trainer.test(model, dm)\n",
    "        # model = CNNTransformer.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
    "        trainer.test(model=model, dataloaders=dm.test_dataloader(), ckpt_path='best')\n",
    "        # trainer.test(dataloaders=dm.test_dataloader(), ckpt_path='best')\n",
    "\n",
    "        # test_pred = model(dm.test_dataloader().dataset.tensors[0])\n",
    "        # test_pred = trainer.predict(model, dm.test_dataloader(), ckpt_path='best)[0]\n",
    "        # test_pred = torch.argmax(test_pred, dim=1)\n",
    "        # print(test_pred)\n",
    "        # y_pred_all.extend(test_pred)\n",
    "        # y_test_all.extend(dm.test_dataloader().dataset.tensors[1])\n",
    "        \n",
    "        fold_accs.append(trainer.logged_metrics['test_acc'])\n",
    "    \n",
    "        # save loss information\n",
    "        # loss_dict = trainer.logger.metrics\n",
    "        # loss_dict['fold'] = fold\n",
    "        # loss_dict['model'] = model\n",
    "    # acc = cmat_acc(torch.stack(y_pred_all), torch.stack(y_test_all), num_classes)\n",
    "    # print(acc)\n",
    "    # iter_accs.append(acc)\n",
    "    # print(f'Averaged accuracy: {sum(fold_accs) / len(fold_accs)}')\n",
    "    iter_accs.append(fold_accs)\n",
    "    print(np.mean(fold_accs))\n",
    "# print(sum(iter_accs) / len(iter_accs), iter_accs)\n",
    "print(iter_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a9b87d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch import tensor\n",
    "# test = [[tensor(0.5000), tensor(0.3636), tensor(0.2727), tensor(0.4545), tensor(0.3182), tensor(0.4545), tensor(0.4091), tensor(0.2273), tensor(0.2727), tensor(0.4091), tensor(0.2727), tensor(0.3182), tensor(0.3333), tensor(0.3333), tensor(0.4762), tensor(0.3333), tensor(0.2857), tensor(0.3810), tensor(0.3810), tensor(0.3810)]]\n",
    "plt.boxplot(fold_accs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc82690e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20790043"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.mean(fold_accs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
